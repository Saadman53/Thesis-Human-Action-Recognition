{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+epFsFd+ZDCm2VRRTXYQu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saadman53/Thesis-Human-Action-Recognition/blob/main/Human_Action_Recognition_using_Sensor_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3tTVmIJXdr_",
        "outputId": "b2f6adf7-155a-4003-c763-0691f04c188b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "gdrive_path = \"drive/My Drive/Dataset/all_data.csv\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install minepy\n",
        "!pip install sklearn_relief\n",
        "!pip install sklearn-genetic\n",
        "!pip install info_gain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvsFKxx7oZ3a",
        "outputId": "81358c13-c239-4733-f4c7-7a5bd43523c4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting minepy\n",
            "  Downloading minepy-1.2.6.tar.gz (496 kB)\n",
            "\u001b[K     |████████████████████████████████| 496 kB 4.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from minepy) (1.21.6)\n",
            "Building wheels for collected packages: minepy\n",
            "  Building wheel for minepy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for minepy: filename=minepy-1.2.6-cp37-cp37m-linux_x86_64.whl size=177588 sha256=9d63861562733a27a5d65d52d4279ab46baa68f5a4659444fc94516798949572\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/71/75/403a33428e468a25c93fa7b672d070b304f36642eb699a29e0\n",
            "Successfully built minepy\n",
            "Installing collected packages: minepy\n",
            "Successfully installed minepy-1.2.6\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sklearn_relief\n",
            "  Downloading sklearn_relief-1.0.0b2-py3-none-any.whl (8.7 kB)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from sklearn_relief) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from sklearn_relief) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from sklearn_relief) (1.21.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->sklearn_relief) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->sklearn_relief) (1.2.0)\n",
            "Installing collected packages: sklearn-relief\n",
            "Successfully installed sklearn-relief-1.0.0b2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sklearn-genetic\n",
            "  Downloading sklearn_genetic-0.5.1-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sklearn-genetic) (1.21.6)\n",
            "Collecting deap>=1.0.2\n",
            "  Downloading deap-1.3.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (139 kB)\n",
            "\u001b[K     |████████████████████████████████| 139 kB 8.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.23 in /usr/local/lib/python3.7/dist-packages (from sklearn-genetic) (1.0.2)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py37-none-any.whl (115 kB)\n",
            "\u001b[K     |████████████████████████████████| 115 kB 53.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.23->sklearn-genetic) (1.7.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.23->sklearn-genetic) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.23->sklearn-genetic) (1.2.0)\n",
            "Requirement already satisfied: dill>=0.3.6 in /usr/local/lib/python3.7/dist-packages (from multiprocess->sklearn-genetic) (0.3.6)\n",
            "Installing collected packages: multiprocess, deap, sklearn-genetic\n",
            "Successfully installed deap-1.3.3 multiprocess-0.70.14 sklearn-genetic-0.5.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting info_gain\n",
            "  Downloading info_gain-1.0.1-py3-none-any.whl (3.3 kB)\n",
            "Installing collected packages: info-gain\n",
            "Successfully installed info-gain-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "from minepy import MINE\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "import scipy\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.special import entr\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from scipy.stats import differential_entropy\n",
        "from scipy.stats import entropy\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "from genetic_selection import GeneticSelectionCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "from info_gain import info_gain"
      ],
      "metadata": {
        "id": "QwUL16kMXhyp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(gdrive_path)\n",
        "df.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "1k6kAkaiXjLA",
        "outputId": "4a646e90-a383-4c7f-f223-84feb66f3bc0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0  0_mean_x   0_var_x   0_kurt_x   0_max_x   0_min_x  \\\n",
              "1160        1160 -0.054506  0.001862  -0.040152  0.072510 -0.149658   \n",
              "1161        1161 -0.026696  0.002853   5.849030  0.427002 -0.189697   \n",
              "1162        1162 -0.038772  0.001957  37.360906  0.555176 -0.434082   \n",
              "1163        1163 -0.084045  0.001579  -0.482562  0.028564 -0.166016   \n",
              "1164        1164 -0.043714  0.001209   0.021406  0.071533 -0.119873   \n",
              "\n",
              "      0_dc_comp_x  0_spec_energy_x  0_spec_entropy_x  0_max_psd_x  ...  \\\n",
              "1160  4178.914871     15331.889818          3.857213     0.420883  ...   \n",
              "1161   842.076824      1492.626785          5.105730     0.373887  ...   \n",
              "1162  1766.442641      2957.616036          6.873023     0.149166  ...   \n",
              "1163  9406.587377     77108.344139          3.375543     0.413470  ...   \n",
              "1164  1880.480207      3743.618849          3.326524     0.543291  ...   \n",
              "\n",
              "       9_dc_comp_m  9_spec_energy_m  9_spec_entropy_m  9_max_psd_m  \\\n",
              "1160  1.338846e+06     1.511391e+09          6.555544     0.113631   \n",
              "1161  1.131603e+06     1.178036e+09          6.289649     0.097086   \n",
              "1162  1.123454e+06     1.164343e+09          6.877409     0.068606   \n",
              "1163  1.274956e+06     1.408591e+09          6.892931     0.061177   \n",
              "1164  9.423824e+05     8.952466e+08          6.628678     0.059656   \n",
              "\n",
              "       9_min_psd_m  9_min_max_psd_m  9_max_xas_m  9_min_xas_m  \\\n",
              "1160  3.274603e-09     2.881788e-08     0.337092     0.000057   \n",
              "1161  1.527362e-08     1.573198e-07     0.311587     0.000124   \n",
              "1162  6.772243e-08     9.871164e-07     0.261928     0.000260   \n",
              "1163  1.379768e-08     2.255369e-07     0.247340     0.000117   \n",
              "1164  1.391945e-07     2.333289e-06     0.244246     0.000373   \n",
              "\n",
              "      9_min_max_xas_m  activity  \n",
              "1160         0.000170         9  \n",
              "1161         0.000397         9  \n",
              "1162         0.000994         9  \n",
              "1163         0.000475         9  \n",
              "1164         0.001528         9  \n",
              "\n",
              "[5 rows x 562 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-525f6935-c863-4e86-af74-2accb47ff96a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>0_mean_x</th>\n",
              "      <th>0_var_x</th>\n",
              "      <th>0_kurt_x</th>\n",
              "      <th>0_max_x</th>\n",
              "      <th>0_min_x</th>\n",
              "      <th>0_dc_comp_x</th>\n",
              "      <th>0_spec_energy_x</th>\n",
              "      <th>0_spec_entropy_x</th>\n",
              "      <th>0_max_psd_x</th>\n",
              "      <th>...</th>\n",
              "      <th>9_dc_comp_m</th>\n",
              "      <th>9_spec_energy_m</th>\n",
              "      <th>9_spec_entropy_m</th>\n",
              "      <th>9_max_psd_m</th>\n",
              "      <th>9_min_psd_m</th>\n",
              "      <th>9_min_max_psd_m</th>\n",
              "      <th>9_max_xas_m</th>\n",
              "      <th>9_min_xas_m</th>\n",
              "      <th>9_min_max_xas_m</th>\n",
              "      <th>activity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1160</th>\n",
              "      <td>1160</td>\n",
              "      <td>-0.054506</td>\n",
              "      <td>0.001862</td>\n",
              "      <td>-0.040152</td>\n",
              "      <td>0.072510</td>\n",
              "      <td>-0.149658</td>\n",
              "      <td>4178.914871</td>\n",
              "      <td>15331.889818</td>\n",
              "      <td>3.857213</td>\n",
              "      <td>0.420883</td>\n",
              "      <td>...</td>\n",
              "      <td>1.338846e+06</td>\n",
              "      <td>1.511391e+09</td>\n",
              "      <td>6.555544</td>\n",
              "      <td>0.113631</td>\n",
              "      <td>3.274603e-09</td>\n",
              "      <td>2.881788e-08</td>\n",
              "      <td>0.337092</td>\n",
              "      <td>0.000057</td>\n",
              "      <td>0.000170</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1161</th>\n",
              "      <td>1161</td>\n",
              "      <td>-0.026696</td>\n",
              "      <td>0.002853</td>\n",
              "      <td>5.849030</td>\n",
              "      <td>0.427002</td>\n",
              "      <td>-0.189697</td>\n",
              "      <td>842.076824</td>\n",
              "      <td>1492.626785</td>\n",
              "      <td>5.105730</td>\n",
              "      <td>0.373887</td>\n",
              "      <td>...</td>\n",
              "      <td>1.131603e+06</td>\n",
              "      <td>1.178036e+09</td>\n",
              "      <td>6.289649</td>\n",
              "      <td>0.097086</td>\n",
              "      <td>1.527362e-08</td>\n",
              "      <td>1.573198e-07</td>\n",
              "      <td>0.311587</td>\n",
              "      <td>0.000124</td>\n",
              "      <td>0.000397</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1162</th>\n",
              "      <td>1162</td>\n",
              "      <td>-0.038772</td>\n",
              "      <td>0.001957</td>\n",
              "      <td>37.360906</td>\n",
              "      <td>0.555176</td>\n",
              "      <td>-0.434082</td>\n",
              "      <td>1766.442641</td>\n",
              "      <td>2957.616036</td>\n",
              "      <td>6.873023</td>\n",
              "      <td>0.149166</td>\n",
              "      <td>...</td>\n",
              "      <td>1.123454e+06</td>\n",
              "      <td>1.164343e+09</td>\n",
              "      <td>6.877409</td>\n",
              "      <td>0.068606</td>\n",
              "      <td>6.772243e-08</td>\n",
              "      <td>9.871164e-07</td>\n",
              "      <td>0.261928</td>\n",
              "      <td>0.000260</td>\n",
              "      <td>0.000994</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1163</th>\n",
              "      <td>1163</td>\n",
              "      <td>-0.084045</td>\n",
              "      <td>0.001579</td>\n",
              "      <td>-0.482562</td>\n",
              "      <td>0.028564</td>\n",
              "      <td>-0.166016</td>\n",
              "      <td>9406.587377</td>\n",
              "      <td>77108.344139</td>\n",
              "      <td>3.375543</td>\n",
              "      <td>0.413470</td>\n",
              "      <td>...</td>\n",
              "      <td>1.274956e+06</td>\n",
              "      <td>1.408591e+09</td>\n",
              "      <td>6.892931</td>\n",
              "      <td>0.061177</td>\n",
              "      <td>1.379768e-08</td>\n",
              "      <td>2.255369e-07</td>\n",
              "      <td>0.247340</td>\n",
              "      <td>0.000117</td>\n",
              "      <td>0.000475</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1164</th>\n",
              "      <td>1164</td>\n",
              "      <td>-0.043714</td>\n",
              "      <td>0.001209</td>\n",
              "      <td>0.021406</td>\n",
              "      <td>0.071533</td>\n",
              "      <td>-0.119873</td>\n",
              "      <td>1880.480207</td>\n",
              "      <td>3743.618849</td>\n",
              "      <td>3.326524</td>\n",
              "      <td>0.543291</td>\n",
              "      <td>...</td>\n",
              "      <td>9.423824e+05</td>\n",
              "      <td>8.952466e+08</td>\n",
              "      <td>6.628678</td>\n",
              "      <td>0.059656</td>\n",
              "      <td>1.391945e-07</td>\n",
              "      <td>2.333289e-06</td>\n",
              "      <td>0.244246</td>\n",
              "      <td>0.000373</td>\n",
              "      <td>0.001528</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 562 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-525f6935-c863-4e86-af74-2accb47ff96a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-525f6935-c863-4e86-af74-2accb47ff96a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-525f6935-c863-4e86-af74-2accb47ff96a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(df.columns[df.isna().any()].tolist(), axis = 1, inplace = True)\n",
        "df.drop(['Unnamed: 0'], axis = 1, inplace = True)"
      ],
      "metadata": {
        "id": "pbCKNbRtXni2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(['activity'], axis = 1)\n",
        "y = df['activity']\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y,test_size=0.3, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val,test_size=0.1, random_state=21)\n",
        "features = X.columns"
      ],
      "metadata": {
        "id": "Qy2_4uGbNGD-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#relief f\n",
        "from sklearn.metrics.pairwise import pairwise_distances\n",
        "def reliefF(X, y, **kwargs):\n",
        "    \"\"\"\n",
        "    This function implements the reliefF feature selection\n",
        "    Input\n",
        "    -----\n",
        "    X: {numpy array}, shape (n_samples, n_features)\n",
        "        input data\n",
        "    y: {numpy array}, shape (n_samples,)\n",
        "        input class labels\n",
        "    kwargs: {dictionary}\n",
        "        parameters of reliefF:\n",
        "        k: {int}\n",
        "            choices for the number of neighbors (default k = 5)\n",
        "    Output\n",
        "    ------\n",
        "    score: {numpy array}, shape (n_features,)\n",
        "        reliefF score for each feature\n",
        "    Reference\n",
        "    ---------\n",
        "    Robnik-Sikonja, Marko et al. \"Theoretical and empirical analysis of relieff and rrelieff.\" Machine Learning 2003.\n",
        "    Zhao, Zheng et al. \"On Similarity Preserving Feature Selection.\" TKDE 2013.\n",
        "    \"\"\"\n",
        "\n",
        "    if \"k\" not in kwargs.keys():\n",
        "        k = 5\n",
        "    else:\n",
        "        k = kwargs[\"k\"]\n",
        "    n_samples, n_features = X.shape\n",
        "\n",
        "    # calculate pairwise distances between instances\n",
        "    distance = pairwise_distances(X, metric='manhattan')\n",
        "\n",
        "    score = np.zeros(n_features)\n",
        "\n",
        "    # the number of sampled instances is equal to the number of total instances\n",
        "    for idx in range(n_samples):\n",
        "        near_hit = []\n",
        "        near_miss = dict()\n",
        "\n",
        "        self_fea = X[idx, :]\n",
        "        c = np.unique(y).tolist()\n",
        "\n",
        "        stop_dict = dict()\n",
        "        for label in c:\n",
        "            stop_dict[label] = 0\n",
        "        del c[c.index(y[idx])]\n",
        "\n",
        "        p_dict = dict()\n",
        "        p_label_idx = float(len(y[y == y[idx]]))/float(n_samples)\n",
        "\n",
        "        for label in c:\n",
        "            p_label_c = float(len(y[y == label]))/float(n_samples)\n",
        "            p_dict[label] = p_label_c/(1-p_label_idx)\n",
        "            near_miss[label] = []\n",
        "\n",
        "        distance_sort = []\n",
        "        distance[idx, idx] = np.max(distance[idx, :])\n",
        "\n",
        "        for i in range(n_samples):\n",
        "            distance_sort.append([distance[idx, i], int(i), y[i]])\n",
        "        distance_sort.sort(key=lambda x: x[0])\n",
        "\n",
        "        for i in range(n_samples):\n",
        "            # find k nearest hit points\n",
        "            if distance_sort[i][2] == y[idx]:\n",
        "                if len(near_hit) < k:\n",
        "                    near_hit.append(distance_sort[i][1])\n",
        "                elif len(near_hit) == k:\n",
        "                    stop_dict[y[idx]] = 1\n",
        "            else:\n",
        "                # find k nearest miss points for each label\n",
        "                if len(near_miss[distance_sort[i][2]]) < k:\n",
        "                    near_miss[distance_sort[i][2]].append(distance_sort[i][1])\n",
        "                else:\n",
        "                    if len(near_miss[distance_sort[i][2]]) == k:\n",
        "                        stop_dict[distance_sort[i][2]] = 1\n",
        "            stop = True\n",
        "            for (key, value) in stop_dict.items():\n",
        "                    if value != 1:\n",
        "                        stop = False\n",
        "            if stop:\n",
        "                break\n",
        "\n",
        "        # update reliefF score\n",
        "        near_hit_term = np.zeros(n_features)\n",
        "        for ele in near_hit:\n",
        "            near_hit_term = np.array(abs(self_fea-X[ele, :]))+np.array(near_hit_term)\n",
        "\n",
        "        near_miss_term = dict()\n",
        "        for (label, miss_list) in near_miss.items():\n",
        "            near_miss_term[label] = np.zeros(n_features)\n",
        "            for ele in miss_list:\n",
        "                near_miss_term[label] = np.array(abs(self_fea-X[ele, :]))+np.array(near_miss_term[label])\n",
        "            score += near_miss_term[label]/(k*p_dict[label])\n",
        "        score -= near_hit_term/k\n",
        "    return score\n",
        "\n",
        "\n",
        "def feature_ranking(score):\n",
        "    \"\"\"\n",
        "    Rank features in descending order according to reliefF score, the higher the reliefF score, the more important the\n",
        "    feature is\n",
        "    \"\"\"\n",
        "    idx = np.argsort(score, 0)\n",
        "    return idx[::-1]\n",
        "def selected_features(X, score):\n",
        "  ranked_features = feature_ranking(score)\n",
        "  sel_feat = []\n",
        "  for i in range(X.shape[1]):\n",
        "    if(ranked_features[i]>0):\n",
        "      sel_feat.append(ranked_features[i])\n",
        "    else:\n",
        "      break\n",
        "  return X.columns[np.array(sel_feat)]\n"
      ],
      "metadata": {
        "id": "od1W19upYUic"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##symmetrical uncertainty\n",
        "def SU(df, X,Y):\n",
        "  if(Y=='activity'):\n",
        "    IG = mutual_info_classif(np.transpose(np.array([df[X]])), df[Y]).item()\n",
        "    H_Y = entropy(df[Y])\n",
        "  else:\n",
        "    IG = mutual_info_regression(np.transpose(np.array([df[X]])), df[Y]).item()\n",
        "    H_Y = differential_entropy(df[Y])\n",
        "  H_X = differential_entropy(df[X])\n",
        "  su = ((2.0*IG)/(H_X+H_Y))\n",
        "  return su\n",
        " \n",
        "def MI(df, X,Y):\n",
        "  if(Y=='activity'):\n",
        "    MI = mutual_info_classif(np.transpose(np.array([df[X]])), df[Y]).item()\n",
        "  else:\n",
        "    MI = mutual_info_regression(np.transpose(np.array([df[X]])), df[Y]).item()\n",
        "  return MI\n",
        "\n",
        "def SU_feature_selection(X_train, y_train):\n",
        "  df_train = df.iloc[X_train.index].copy()\n",
        "  scores = []\n",
        "  #print(\"SU:\\nCol\\tScore\")\n",
        "  for col in df_train.columns:\n",
        "    if col!='activity':\n",
        "      #print(col+\":\")\n",
        "      score = SU(df_train, col, 'activity')\n",
        "      scores.append(score)\n",
        "      #print(score)\n",
        "  ser = pd.Series(np.array(scores),index = features).sort_values(ascending=False)\n",
        "  return ser[ser>0.0].index.values\n",
        "\n",
        "#Fast Correlation Based Filter\n",
        "def FCBF(df, features, C):\n",
        "  thresh = 0.000001\n",
        "  N = len(features)\n",
        "  S_list = {}\n",
        "  for i in range(N):\n",
        "    val = SU(df, features[i], C)\n",
        "    if(val> thresh):\n",
        "      S_list[features[i]] = val\n",
        "  S_list = pd.Series(S_list).sort_values(ascending=False)\n",
        "  no_features = S_list.shape[0]\n",
        "  a_list = np.ones(no_features)\n",
        "  for i in range(no_features):\n",
        "    if(a_list[i]==1):\n",
        "      Fp = S_list.index[i]\n",
        "      for j in range(i+1,no_features):\n",
        "        if(a_list[j]==1):\n",
        "          Fq = S_list.index[j]\n",
        "          if(SU(df, Fp,Fq) >= S_list[j]):\n",
        "            print(f\"{j} has been eleminated while in {i}\")\n",
        "            a_list[j]=0\n",
        "  idx = np.where(a_list==1)[0]\n",
        "  return S_list.index[idx]\n",
        "\n",
        "def random_forest_feature_selection(X_train, y_train):\n",
        "  sel = SelectFromModel(RandomForestClassifier(n_estimators = 100))\n",
        "  sel.fit(X_train, y_train)\n",
        "  sel.get_support()\n",
        "  selected_features_rf= X_train.columns[(sel.get_support())].values\n",
        "  return selected_features_rf\n",
        "\n",
        "def reliefF_feature_selection(X_train, y_train):\n",
        "  score = reliefF(X_train.to_numpy(),y_train.to_numpy())\n",
        "  selected_features_relief = selected_features(X_train,score).values\n",
        "  return selected_features_relief\n",
        "\n",
        "def genetic_feature_selection(X_train, y_train):\n",
        "  estimator = DecisionTreeClassifier()\n",
        "  model = GeneticSelectionCV(\n",
        "      estimator, cv=5, verbose=0,\n",
        "      scoring=\"accuracy\", max_features=100,\n",
        "      n_population=100, crossover_proba=0.5,\n",
        "      mutation_proba=0.2, n_generations=50,\n",
        "      crossover_independent_proba=0.5,\n",
        "      mutation_independent_proba=0.04,\n",
        "      tournament_size=3, n_gen_no_change=10,\n",
        "      caching=True, n_jobs=-1)\n",
        "  model = model.fit(X_train,y_train)\n",
        "  selected_features_genetic = X_train.columns[model._get_support_mask()].values\n",
        "  return selected_features_genetic\n",
        "\n",
        "def mutual_information_feature_selection(X_train, y_train):\n",
        "  mi_scores = mutual_info_regression(X_train, y_train, discrete_features=False)\n",
        "  mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
        "  mi_scores = mi_scores.sort_values(ascending=False)\n",
        "  selected_features_info_gain = mi_scores[mi_scores>0.5].index.values\n",
        "  return selected_features_info_gain\n",
        "\n",
        "# def information_gain_feature_selection(X_train, y_train):\n",
        "#   clf = DecisionTreeClassifier(random_state=0, criterion = \"entropy\")\n",
        "#   clf.fit(X_train, y_train)\n",
        "#   scores = clf.feature_importances_\n",
        "#   ser = pd.Series(scores, index = features).sort_values(ascending=False)\n",
        "#   return ser[ser>0.0]\n",
        "def gain_ratio_feature_selection(X_train, y_train):\n",
        "  gain_ratio = []\n",
        "  print(\"Gain Ratio:\\nCol\\tScore\")\n",
        "  for i in range(X_train.shape[1]):\n",
        "    score = info_gain.info_gain_ratio(X_train.iloc[:,i], y_train )\n",
        "    gain_ratio.append(score)\n",
        "    print(X_train.columns[i],score)\n",
        "  res = pd.Series(np.array(gain_ratio),index = features).sort_values(ascending=False)\n",
        "  return res[res>0.60].index.values\n",
        "\n",
        "def chi2_feature_selection(X_train1,y_train):\n",
        "  scaler = MinMaxScaler()\n",
        "  X_train1 = scaler.fit_transform(X_train)\n",
        "  from sklearn.feature_selection import chi2\n",
        "  chi_scores = chi2(X_train1,y_train)\n",
        "  p_values = pd.Series(chi_scores[1],index = X.columns)\n",
        "  p_values.sort_values(ascending = False , inplace = True)\n",
        "  selected_features_chi = p_values[p_values>0.5].index.values\n",
        "  return selected_features_chi"
      ],
      "metadata": {
        "id": "c4MRBs1NRCjX"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def EFS_MI(df, X_train, y_train):\n",
        "  selected_feature_list = [gain_ratio_feature_selection(X_train, y_train),\n",
        "                           reliefF_feature_selection(X_train,y_train), \n",
        "                           SU_feature_selection(X_train, y_train), \n",
        "                           mutual_information_feature_selection(X_train,y_train), \n",
        "                           chi2_feature_selection(X_train,y_train)]\n",
        "  s = set()\n",
        "  df_train = df.iloc[X_train.index]\n",
        "  for i in range(5):\n",
        "    for j in range(len(selected_feature_list[i])):\n",
        "      s.add(selected_feature_list[i][j])\n",
        "  optimal_list = []\n",
        "  ensemble_list = []\n",
        "  for feat in s:\n",
        "    cnt = 0\n",
        "    for j in range(5):\n",
        "      if(feat in selected_feature_list[j]):\n",
        "        cnt+=1\n",
        "    if(cnt==5):\n",
        "      optimal_list.append(feat)\n",
        "    else:\n",
        "      ensemble_list.append(feat)\n",
        "  f_class_mi = []\n",
        "  for feature in ensemble_list:\n",
        "    score = MI(df_train, feature, 'activity')\n",
        "    f_class_mi.append(score)\n",
        "  f_class_mi = pd.Series(np.array(f_class_mi),index = ensemble_list).sort_values(ascending=False)\n",
        "  ensemble_list= f_class_mi.index.values\n",
        "  print(len(optimal_list))\n",
        "  print(len(ensemble_list))\n",
        "  for feature in ensemble_list:\n",
        "    scores = []\n",
        "    for opt_feature in optimal_list:\n",
        "      scores.append(MI(df_train,feature,opt_feature))\n",
        "    if (max(scores)<0.75):\n",
        "      optimal_list.append(feature)\n",
        "  return optimal_list\n"
      ],
      "metadata": {
        "id": "_Z-9KZm3rZF2"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ECFS(df,X_train,y_train):\n",
        "  selected_feature_list = [random_forest_feature_selection(X_train,y_train),\n",
        "                           reliefF_feature_selection(X_train,y_train), \n",
        "                           genetic_feature_selection(X_train,y_train), \n",
        "                           mutual_information_feature_selection(X_train,y_train), \n",
        "                           chi2_feature_selection(X_train,y_train)]\n",
        "  s = set()\n",
        "  df_train = df.iloc[X_train.index]\n",
        "  for i in range(5):\n",
        "    for j in range(len(selected_feature_list[i])):\n",
        "      s.add(selected_feature_list[i][j])\n",
        "  final_list = []\n",
        "  ensemble_list = []\n",
        "  for feat in s:\n",
        "    cnt = 0\n",
        "    for j in range(5):\n",
        "      if(feat in selected_feature_list[j]):\n",
        "        cnt+=1\n",
        "    if(cnt>=4):\n",
        "      final_list.append(feat)\n",
        "    else:\n",
        "      ensemble_list.append(feat)\n",
        "  sel = FCBF(df_train, ensemble_list, 'activity')\n",
        "  final_list.extend(sel.values.tolist())\n",
        "  return final_list"
      ],
      "metadata": {
        "id": "EvmtcTLd8Rig"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_feat_ecfs = ECFS(df, X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3NsnerKMvcG",
        "outputId": "89b02fd6-07d5-41e1-d4b9-cd3725908b17"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "323 has been eleminated while in 0\n",
            "327 has been eleminated while in 0\n",
            "328 has been eleminated while in 0\n",
            "330 has been eleminated while in 0\n",
            "333 has been eleminated while in 0\n",
            "335 has been eleminated while in 0\n",
            "317 has been eleminated while in 1\n",
            "324 has been eleminated while in 1\n",
            "334 has been eleminated while in 1\n",
            "329 has been eleminated while in 2\n",
            "332 has been eleminated while in 2\n",
            "315 has been eleminated while in 5\n",
            "202 has been eleminated while in 16\n",
            "287 has been eleminated while in 16\n",
            "308 has been eleminated while in 18\n",
            "313 has been eleminated while in 18\n",
            "237 has been eleminated while in 19\n",
            "243 has been eleminated while in 19\n",
            "288 has been eleminated while in 19\n",
            "331 has been eleminated while in 22\n",
            "228 has been eleminated while in 24\n",
            "257 has been eleminated while in 24\n",
            "295 has been eleminated while in 24\n",
            "302 has been eleminated while in 24\n",
            "320 has been eleminated while in 24\n",
            "297 has been eleminated while in 28\n",
            "209 has been eleminated while in 29\n",
            "248 has been eleminated while in 29\n",
            "281 has been eleminated while in 29\n",
            "293 has been eleminated while in 29\n",
            "296 has been eleminated while in 29\n",
            "298 has been eleminated while in 29\n",
            "316 has been eleminated while in 29\n",
            "33 has been eleminated while in 31\n",
            "34 has been eleminated while in 31\n",
            "45 has been eleminated while in 31\n",
            "47 has been eleminated while in 31\n",
            "48 has been eleminated while in 31\n",
            "50 has been eleminated while in 31\n",
            "52 has been eleminated while in 31\n",
            "55 has been eleminated while in 31\n",
            "57 has been eleminated while in 31\n",
            "58 has been eleminated while in 31\n",
            "60 has been eleminated while in 31\n",
            "61 has been eleminated while in 31\n",
            "62 has been eleminated while in 31\n",
            "64 has been eleminated while in 31\n",
            "70 has been eleminated while in 31\n",
            "71 has been eleminated while in 31\n",
            "72 has been eleminated while in 31\n",
            "75 has been eleminated while in 31\n",
            "82 has been eleminated while in 31\n",
            "83 has been eleminated while in 31\n",
            "84 has been eleminated while in 31\n",
            "85 has been eleminated while in 31\n",
            "87 has been eleminated while in 31\n",
            "88 has been eleminated while in 31\n",
            "89 has been eleminated while in 31\n",
            "92 has been eleminated while in 31\n",
            "95 has been eleminated while in 31\n",
            "100 has been eleminated while in 31\n",
            "103 has been eleminated while in 31\n",
            "110 has been eleminated while in 31\n",
            "112 has been eleminated while in 31\n",
            "120 has been eleminated while in 31\n",
            "121 has been eleminated while in 31\n",
            "125 has been eleminated while in 31\n",
            "128 has been eleminated while in 31\n",
            "130 has been eleminated while in 31\n",
            "133 has been eleminated while in 31\n",
            "134 has been eleminated while in 31\n",
            "136 has been eleminated while in 31\n",
            "137 has been eleminated while in 31\n",
            "139 has been eleminated while in 31\n",
            "147 has been eleminated while in 31\n",
            "152 has been eleminated while in 31\n",
            "153 has been eleminated while in 31\n",
            "156 has been eleminated while in 31\n",
            "157 has been eleminated while in 31\n",
            "164 has been eleminated while in 31\n",
            "169 has been eleminated while in 31\n",
            "177 has been eleminated while in 31\n",
            "179 has been eleminated while in 31\n",
            "180 has been eleminated while in 31\n",
            "181 has been eleminated while in 31\n",
            "186 has been eleminated while in 31\n",
            "195 has been eleminated while in 31\n",
            "197 has been eleminated while in 31\n",
            "200 has been eleminated while in 31\n",
            "201 has been eleminated while in 31\n",
            "212 has been eleminated while in 31\n",
            "219 has been eleminated while in 31\n",
            "224 has been eleminated while in 31\n",
            "231 has been eleminated while in 31\n",
            "232 has been eleminated while in 31\n",
            "247 has been eleminated while in 31\n",
            "254 has been eleminated while in 31\n",
            "256 has been eleminated while in 31\n",
            "258 has been eleminated while in 31\n",
            "261 has been eleminated while in 31\n",
            "270 has been eleminated while in 31\n",
            "279 has been eleminated while in 31\n",
            "280 has been eleminated while in 31\n",
            "285 has been eleminated while in 31\n",
            "290 has been eleminated while in 31\n",
            "294 has been eleminated while in 31\n",
            "301 has been eleminated while in 31\n",
            "303 has been eleminated while in 31\n",
            "305 has been eleminated while in 31\n",
            "309 has been eleminated while in 31\n",
            "310 has been eleminated while in 31\n",
            "311 has been eleminated while in 31\n",
            "314 has been eleminated while in 31\n",
            "206 has been eleminated while in 32\n",
            "220 has been eleminated while in 32\n",
            "319 has been eleminated while in 38\n",
            "211 has been eleminated while in 40\n",
            "260 has been eleminated while in 41\n",
            "322 has been eleminated while in 54\n",
            "326 has been eleminated while in 69\n",
            "307 has been eleminated while in 101\n",
            "325 has been eleminated while in 145\n",
            "291 has been eleminated while in 170\n",
            "318 has been eleminated while in 170\n",
            "235 has been eleminated while in 190\n",
            "215 has been eleminated while in 198\n",
            "218 has been eleminated while in 198\n",
            "225 has been eleminated while in 198\n",
            "227 has been eleminated while in 198\n",
            "229 has been eleminated while in 198\n",
            "233 has been eleminated while in 198\n",
            "234 has been eleminated while in 198\n",
            "236 has been eleminated while in 198\n",
            "238 has been eleminated while in 198\n",
            "239 has been eleminated while in 198\n",
            "240 has been eleminated while in 198\n",
            "241 has been eleminated while in 198\n",
            "244 has been eleminated while in 198\n",
            "246 has been eleminated while in 198\n",
            "252 has been eleminated while in 198\n",
            "259 has been eleminated while in 198\n",
            "264 has been eleminated while in 198\n",
            "267 has been eleminated while in 198\n",
            "268 has been eleminated while in 198\n",
            "269 has been eleminated while in 198\n",
            "271 has been eleminated while in 198\n",
            "273 has been eleminated while in 198\n",
            "276 has been eleminated while in 198\n",
            "277 has been eleminated while in 198\n",
            "278 has been eleminated while in 198\n",
            "282 has been eleminated while in 198\n",
            "286 has been eleminated while in 198\n",
            "292 has been eleminated while in 198\n",
            "266 has been eleminated while in 204\n",
            "284 has been eleminated while in 223\n",
            "251 has been eleminated while in 245\n",
            "299 has been eleminated while in 249\n",
            "274 has been eleminated while in 272\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "selected_feat_efs_mi = EFS_MI(df, X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDVM6fyAAbyC",
        "outputId": "346a4364-2260-4465-fcb4-33afe62b3da7"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gain Ratio:\n",
            "Col\tScore\n",
            "0_mean_x 0.6931471805599454\n",
            "0_var_x 0.6931471805599454\n",
            "0_kurt_x 0.6931471805599454\n",
            "0_max_x 0.6442340236467442\n",
            "0_min_x 0.6474469203236148\n",
            "0_dc_comp_x 0.6931471805599454\n",
            "0_spec_energy_x 0.6931471805599454\n",
            "0_spec_entropy_x 0.6931471805599454\n",
            "0_max_psd_x 0.6931471805599454\n",
            "0_min_psd_x 0.6931471805599454\n",
            "0_min_max_psd_x 0.6931471805599454\n",
            "0_max_xas_x 0.6931471805599454\n",
            "0_min_xas_x 0.6931471805599454\n",
            "0_min_max_xas_x 0.6931471805599454\n",
            "0_mean_y 0.6931471805599454\n",
            "0_var_y 0.6931471805599454\n",
            "0_kurt_y 0.6931471805599454\n",
            "0_max_y 0.6039250954828004\n",
            "0_min_y 0.5932354764513097\n",
            "0_dc_comp_y 0.6931471805599454\n",
            "0_spec_energy_y 0.6931471805599454\n",
            "0_spec_entropy_y 0.6931471805599454\n",
            "0_max_psd_y 0.6931471805599454\n",
            "0_min_psd_y 0.6931471805599454\n",
            "0_min_max_psd_y 0.6931471805599454\n",
            "0_max_xas_y 0.6931471805599454\n",
            "0_min_xas_y 0.6931471805599454\n",
            "0_min_max_xas_y 0.6931471805599454\n",
            "0_mean_z 0.6931471805599454\n",
            "0_var_z 0.6931471805599454\n",
            "0_kurt_z 0.6931471805599454\n",
            "0_max_z 0.6171509330448822\n",
            "0_min_z 0.6347447697735448\n",
            "0_dc_comp_z 0.6931471805599454\n",
            "0_spec_energy_z 0.6931471805599454\n",
            "0_max_psd_z 0.6931471805599454\n",
            "0_min_psd_z 0.6931471805599454\n",
            "0_min_max_psd_z 0.6931471805599454\n",
            "0_max_xas_z 0.6931471805599454\n",
            "0_min_xas_z 0.6931471805599454\n",
            "0_min_max_xas_z 0.6931471805599454\n",
            "0_mean_m 0.6931471805599454\n",
            "0_var_m 0.6931471805599454\n",
            "0_kurt_m 0.6931471805599454\n",
            "0_max_m 0.6931471805599454\n",
            "0_min_m 0.6931471805599454\n",
            "0_dc_comp_m 0.6931471805599454\n",
            "0_spec_energy_m 0.6931471805599454\n",
            "0_spec_entropy_m 0.6931471805599454\n",
            "0_max_psd_m 0.6931471805599454\n",
            "0_min_psd_m 0.6931471805599454\n",
            "0_min_max_psd_m 0.6931471805599454\n",
            "0_max_xas_m 0.6931471805599454\n",
            "0_min_xas_m 0.6931471805599454\n",
            "0_min_max_xas_m 0.6931471805599454\n",
            "1_mean_x 0.6931471805599454\n",
            "1_var_x 0.6931471805599454\n",
            "1_kurt_x 0.6931471805599454\n",
            "1_max_x 0.6402698056928214\n",
            "1_min_x 0.6398448029298001\n",
            "1_dc_comp_x 0.6931471805599454\n",
            "1_spec_energy_x 0.6931471805599454\n",
            "1_max_psd_x 0.6931471805599454\n",
            "1_min_psd_x 0.6931471805599454\n",
            "1_min_max_psd_x 0.6931471805599454\n",
            "1_max_xas_x 0.6931471805599454\n",
            "1_min_xas_x 0.6931471805599454\n",
            "1_min_max_xas_x 0.6931471805599454\n",
            "1_mean_y 0.6931471805599454\n",
            "1_var_y 0.6931471805599454\n",
            "1_kurt_y 0.6931471805599454\n",
            "1_max_y 0.5982101145683698\n",
            "1_min_y 0.5677195783595105\n",
            "1_dc_comp_y 0.6931471805599454\n",
            "1_spec_energy_y 0.6931471805599454\n",
            "1_spec_entropy_y 0.6931471805599454\n",
            "1_max_psd_y 0.6931471805599454\n",
            "1_min_psd_y 0.6931471805599454\n",
            "1_min_max_psd_y 0.6931471805599454\n",
            "1_max_xas_y 0.6931471805599454\n",
            "1_min_xas_y 0.6931471805599454\n",
            "1_min_max_xas_y 0.6931471805599454\n",
            "1_mean_z 0.6931471805599454\n",
            "1_var_z 0.6931471805599454\n",
            "1_kurt_z 0.6931471805599454\n",
            "1_max_z 0.6365489543144613\n",
            "1_min_z 0.6419485951945432\n",
            "1_dc_comp_z 0.6931471805599454\n",
            "1_spec_energy_z 0.6931471805599454\n",
            "1_max_psd_z 0.6931471805599454\n",
            "1_min_psd_z 0.6931471805599454\n",
            "1_min_max_psd_z 0.6931471805599454\n",
            "1_max_xas_z 0.6931471805599454\n",
            "1_min_xas_z 0.6931471805599454\n",
            "1_min_max_xas_z 0.6931471805599454\n",
            "1_mean_m 0.6931471805599454\n",
            "1_var_m 0.6931471805599454\n",
            "1_kurt_m 0.6931471805599454\n",
            "1_max_m 0.6931471805599454\n",
            "1_min_m 0.6931471805599454\n",
            "1_dc_comp_m 0.6931471805599454\n",
            "1_spec_energy_m 0.6931471805599454\n",
            "1_spec_entropy_m 0.6931471805599454\n",
            "1_max_psd_m 0.6931471805599454\n",
            "1_min_psd_m 0.6931471805599454\n",
            "1_min_max_psd_m 0.6931471805599454\n",
            "1_max_xas_m 0.6931471805599454\n",
            "1_min_xas_m 0.6931471805599454\n",
            "1_min_max_xas_m 0.6931471805599454\n",
            "2_mean_x 0.6931471805599454\n",
            "2_var_x 0.6931471805599454\n",
            "2_kurt_x 0.6931471805599454\n",
            "2_max_x 0.6637657487632136\n",
            "2_min_x 0.6493423656106946\n",
            "2_dc_comp_x 0.6931471805599454\n",
            "2_spec_energy_x 0.6931471805599454\n",
            "2_max_psd_x 0.6931471805599454\n",
            "2_min_psd_x 0.6931471805599454\n",
            "2_min_max_psd_x 0.6931471805599454\n",
            "2_max_xas_x 0.6931471805599454\n",
            "2_min_xas_x 0.6931471805599454\n",
            "2_min_max_xas_x 0.6931471805599454\n",
            "2_mean_y 0.6931471805599454\n",
            "2_var_y 0.6931471805599454\n",
            "2_kurt_y 0.6931471805599454\n",
            "2_max_y 0.6487274178525201\n",
            "2_min_y 0.6065792855497596\n",
            "2_dc_comp_y 0.6931471805599454\n",
            "2_spec_energy_y 0.6931471805599454\n",
            "2_max_psd_y 0.6931471805599454\n",
            "2_min_psd_y 0.6931471805599454\n",
            "2_min_max_psd_y 0.6931471805599454\n",
            "2_max_xas_y 0.6931471805599454\n",
            "2_min_xas_y 0.6931471805599454\n",
            "2_min_max_xas_y 0.6931471805599454\n",
            "2_mean_z 0.6931471805599454\n",
            "2_var_z 0.6931471805599454\n",
            "2_kurt_z 0.6931471805599454\n",
            "2_max_z 0.6672699443562153\n",
            "2_min_z 0.6607344882738013\n",
            "2_dc_comp_z 0.6931471805599454\n",
            "2_spec_energy_z 0.6931471805599454\n",
            "2_max_psd_z 0.6931471805599454\n",
            "2_min_psd_z 0.6931471805599454\n",
            "2_min_max_psd_z 0.6931471805599454\n",
            "2_max_xas_z 0.6931471805599454\n",
            "2_min_xas_z 0.6931471805599454\n",
            "2_min_max_xas_z 0.6931471805599454\n",
            "2_mean_m 0.6931471805599454\n",
            "2_var_m 0.6931471805599454\n",
            "2_kurt_m 0.6931471805599454\n",
            "2_max_m 0.6931471805599454\n",
            "2_min_m 0.6931471805599454\n",
            "2_dc_comp_m 0.6931471805599454\n",
            "2_spec_energy_m 0.6931471805599454\n",
            "2_max_psd_m 0.6931471805599454\n",
            "2_min_psd_m 0.6931471805599454\n",
            "2_min_max_psd_m 0.6931471805599454\n",
            "2_max_xas_m 0.6931471805599454\n",
            "2_min_xas_m 0.6931471805599454\n",
            "2_min_max_xas_m 0.6931471805599454\n",
            "3_mean_x 0.6931471805599454\n",
            "3_var_x 0.6931471805599454\n",
            "3_kurt_x 0.6931471805599454\n",
            "3_max_x 0.6745512324758407\n",
            "3_min_x 0.6682803645193529\n",
            "3_dc_comp_x 0.6931471805599454\n",
            "3_spec_energy_x 0.6931471805599454\n",
            "3_spec_entropy_x 0.6931471805599454\n",
            "3_max_psd_x 0.6931471805599454\n",
            "3_min_psd_x 0.6931471805599454\n",
            "3_min_max_psd_x 0.6931471805599454\n",
            "3_max_xas_x 0.6931471805599454\n",
            "3_min_xas_x 0.6931471805599454\n",
            "3_min_max_xas_x 0.6931471805599454\n",
            "3_mean_y 0.6931471805599454\n",
            "3_var_y 0.6931471805599454\n",
            "3_kurt_y 0.6931471805599454\n",
            "3_max_y 0.6555837032091237\n",
            "3_min_y 0.6395377717031466\n",
            "3_dc_comp_y 0.6931471805599454\n",
            "3_spec_energy_y 0.6931471805599454\n",
            "3_max_psd_y 0.6931471805599454\n",
            "3_min_psd_y 0.6931471805599454\n",
            "3_min_max_psd_y 0.6931471805599454\n",
            "3_max_xas_y 0.6931471805599454\n",
            "3_min_xas_y 0.6931471805599454\n",
            "3_min_max_xas_y 0.6931471805599454\n",
            "3_mean_z 0.6931471805599454\n",
            "3_var_z 0.6931471805599454\n",
            "3_kurt_z 0.6931471805599454\n",
            "3_max_z 0.6748720617500303\n",
            "3_min_z 0.658392818673337\n",
            "3_dc_comp_z 0.6931471805599454\n",
            "3_spec_energy_z 0.6931471805599454\n",
            "3_spec_entropy_z 0.6931471805599454\n",
            "3_max_psd_z 0.6931471805599454\n",
            "3_min_psd_z 0.6931471805599454\n",
            "3_min_max_psd_z 0.6931471805599454\n",
            "3_max_xas_z 0.6931471805599454\n",
            "3_min_xas_z 0.6931471805599454\n",
            "3_min_max_xas_z 0.6931471805599454\n",
            "3_mean_m 0.6931471805599454\n",
            "3_var_m 0.6931471805599454\n",
            "3_kurt_m 0.6931471805599454\n",
            "3_max_m 0.6931471805599454\n",
            "3_min_m 0.6931471805599454\n",
            "3_dc_comp_m 0.6931471805599454\n",
            "3_spec_energy_m 0.6931471805599454\n",
            "3_max_psd_m 0.6931471805599454\n",
            "3_min_psd_m 0.6931471805599454\n",
            "3_min_max_psd_m 0.6931471805599454\n",
            "3_max_xas_m 0.6931471805599454\n",
            "3_min_xas_m 0.6931471805599454\n",
            "3_min_max_xas_m 0.6931471805599454\n",
            "4_mean_x 0.6931471805599454\n",
            "4_var_x 0.6931471805599454\n",
            "4_kurt_x 0.6931471805599454\n",
            "4_max_x 0.6581844716956736\n",
            "4_min_x 0.6725303921495656\n",
            "4_dc_comp_x 0.6931471805599454\n",
            "4_spec_energy_x 0.6931471805599454\n",
            "4_spec_entropy_x 0.6931471805599454\n",
            "4_max_psd_x 0.6931471805599454\n",
            "4_min_psd_x 0.6931471805599454\n",
            "4_min_max_psd_x 0.6931471805599454\n",
            "4_max_xas_x 0.6931471805599454\n",
            "4_min_xas_x 0.6931471805599454\n",
            "4_min_max_xas_x 0.6931471805599454\n",
            "4_mean_y 0.6931471805599454\n",
            "4_var_y 0.6931471805599454\n",
            "4_kurt_y 0.6931471805599454\n",
            "4_max_y 0.6674782913338786\n",
            "4_min_y 0.6355652449415288\n",
            "4_dc_comp_y 0.6931471805599454\n",
            "4_spec_energy_y 0.6931471805599454\n",
            "4_spec_entropy_y 0.6931471805599454\n",
            "4_max_psd_y 0.6931471805599454\n",
            "4_min_psd_y 0.6931471805599454\n",
            "4_min_max_psd_y 0.6931471805599454\n",
            "4_max_xas_y 0.6931471805599454\n",
            "4_min_xas_y 0.6931471805599454\n",
            "4_min_max_xas_y 0.6931471805599454\n",
            "4_mean_z 0.6931471805599454\n",
            "4_var_z 0.6931471805599454\n",
            "4_kurt_z 0.6931471805599454\n",
            "4_max_z 0.6628595020889076\n",
            "4_min_z 0.6707741399492172\n",
            "4_dc_comp_z 0.6931471805599454\n",
            "4_spec_energy_z 0.6931471805599454\n",
            "4_max_psd_z 0.6931471805599454\n",
            "4_min_psd_z 0.6931471805599454\n",
            "4_min_max_psd_z 0.6931471805599454\n",
            "4_max_xas_z 0.6931471805599454\n",
            "4_min_xas_z 0.6931471805599454\n",
            "4_min_max_xas_z 0.6931471805599454\n",
            "4_mean_m 0.6931471805599454\n",
            "4_var_m 0.6931471805599454\n",
            "4_kurt_m 0.6931471805599454\n",
            "4_max_m 0.6931471805599454\n",
            "4_min_m 0.6931471805599454\n",
            "4_dc_comp_m 0.6931471805599454\n",
            "4_spec_energy_m 0.6931471805599454\n",
            "4_max_psd_m 0.6931471805599454\n",
            "4_min_psd_m 0.6931471805599454\n",
            "4_min_max_psd_m 0.6931471805599454\n",
            "4_max_xas_m 0.6931471805599454\n",
            "4_min_xas_m 0.6931471805599454\n",
            "4_min_max_xas_m 0.6931471805599454\n",
            "5_mean_x 0.6931471805599454\n",
            "5_var_x 0.6931471805599454\n",
            "5_kurt_x 0.6931471805599454\n",
            "5_max_x 0.6676949471192366\n",
            "5_min_x 0.6765158316538521\n",
            "5_dc_comp_x 0.6931471805599454\n",
            "5_spec_energy_x 0.6931471805599454\n",
            "5_spec_entropy_x 0.6931471805599454\n",
            "5_max_psd_x 0.6931471805599454\n",
            "5_min_psd_x 0.6931471805599454\n",
            "5_min_max_psd_x 0.6931471805599454\n",
            "5_max_xas_x 0.6931471805599454\n",
            "5_min_xas_x 0.6931471805599454\n",
            "5_min_max_xas_x 0.6931471805599454\n",
            "5_mean_y 0.6931471805599454\n",
            "5_var_y 0.6931471805599454\n",
            "5_kurt_y 0.6931471805599454\n",
            "5_max_y 0.6741262297128194\n",
            "5_min_y 0.6593820172861107\n",
            "5_dc_comp_y 0.6931471805599454\n",
            "5_spec_energy_y 0.6931471805599454\n",
            "5_spec_entropy_y 0.6931471805599454\n",
            "5_max_psd_y 0.6931471805599454\n",
            "5_min_psd_y 0.6931471805599454\n",
            "5_min_max_psd_y 0.6931471805599454\n",
            "5_max_xas_y 0.6931471805599454\n",
            "5_min_xas_y 0.6931471805599454\n",
            "5_min_max_xas_y 0.6931471805599454\n",
            "5_mean_z 0.6931471805599454\n",
            "5_var_z 0.6931471805599454\n",
            "5_kurt_z 0.6931471805599454\n",
            "5_max_z 0.6776304253058213\n",
            "5_min_z 0.6592428241993792\n",
            "5_dc_comp_z 0.6931471805599454\n",
            "5_spec_energy_z 0.6931471805599454\n",
            "5_spec_entropy_z 0.6931471805599454\n",
            "5_max_psd_z 0.6931471805599454\n",
            "5_min_psd_z 0.6931471805599454\n",
            "5_min_max_psd_z 0.6931471805599454\n",
            "5_max_xas_z 0.6931471805599454\n",
            "5_min_xas_z 0.6931471805599454\n",
            "5_min_max_xas_z 0.6931471805599454\n",
            "5_mean_m 0.6931471805599454\n",
            "5_var_m 0.6931471805599454\n",
            "5_kurt_m 0.6931471805599454\n",
            "5_max_m 0.6931471805599454\n",
            "5_min_m 0.6931471805599454\n",
            "5_dc_comp_m 0.6931471805599454\n",
            "5_spec_energy_m 0.6931471805599454\n",
            "5_max_psd_m 0.6931471805599454\n",
            "5_min_psd_m 0.6931471805599454\n",
            "5_min_max_psd_m 0.6931471805599454\n",
            "5_max_xas_m 0.6931471805599454\n",
            "5_min_xas_m 0.6931471805599454\n",
            "5_min_max_xas_m 0.6931471805599454\n",
            "6_mean_x 0.6931471805599454\n",
            "6_var_x 0.6931471805599454\n",
            "6_kurt_x 0.6931471805599454\n",
            "6_max_x 0.6434402592689649\n",
            "6_min_x 0.6505261131535955\n",
            "6_dc_comp_x 0.6931471805599454\n",
            "6_spec_energy_x 0.6931471805599454\n",
            "6_spec_entropy_x 0.6931471805599454\n",
            "6_max_psd_x 0.6931471805599454\n",
            "6_min_psd_x 0.6931471805599454\n",
            "6_min_max_psd_x 0.6931471805599454\n",
            "6_max_xas_x 0.6931471805599454\n",
            "6_min_xas_x 0.6931471805599454\n",
            "6_min_max_xas_x 0.6931471805599454\n",
            "6_mean_y 0.6931471805599454\n",
            "6_var_y 0.6931471805599454\n",
            "6_kurt_y 0.6931471805599454\n",
            "6_max_y 0.6099442880560302\n",
            "6_min_y 0.6150314084696169\n",
            "6_dc_comp_y 0.6931471805599454\n",
            "6_spec_energy_y 0.6931471805599454\n",
            "6_spec_entropy_y 0.6931471805599454\n",
            "6_max_psd_y 0.6931471805599454\n",
            "6_min_psd_y 0.6931471805599454\n",
            "6_min_max_psd_y 0.6931471805599454\n",
            "6_max_xas_y 0.6931471805599454\n",
            "6_min_xas_y 0.6931471805599454\n",
            "6_min_max_xas_y 0.6931471805599454\n",
            "6_mean_z 0.6931471805599454\n",
            "6_var_z 0.6931471805599454\n",
            "6_kurt_z 0.6931471805599454\n",
            "6_max_z 0.6603574178513482\n",
            "6_min_z 0.6436218954564233\n",
            "6_dc_comp_z 0.6931471805599454\n",
            "6_spec_energy_z 0.6931471805599454\n",
            "6_spec_entropy_z 0.6931471805599454\n",
            "6_max_psd_z 0.6931471805599454\n",
            "6_min_psd_z 0.6931471805599454\n",
            "6_min_max_psd_z 0.6931471805599454\n",
            "6_max_xas_z 0.6931471805599454\n",
            "6_min_xas_z 0.6931471805599454\n",
            "6_min_max_xas_z 0.6931471805599454\n",
            "6_mean_m 0.6931471805599454\n",
            "6_var_m 0.6931471805599454\n",
            "6_kurt_m 0.6931471805599454\n",
            "6_max_m 0.6931471805599454\n",
            "6_min_m 0.6931471805599454\n",
            "6_dc_comp_m 0.6931471805599454\n",
            "6_spec_energy_m 0.6931471805599454\n",
            "6_spec_entropy_m 0.6931471805599454\n",
            "6_max_psd_m 0.6931471805599454\n",
            "6_min_psd_m 0.6931471805599454\n",
            "6_min_max_psd_m 0.6931471805599454\n",
            "6_max_xas_m 0.6931471805599454\n",
            "6_min_xas_m 0.6931471805599454\n",
            "6_min_max_xas_m 0.6931471805599454\n",
            "7_mean_x 0.6931471805599454\n",
            "7_var_x 0.6931471805599454\n",
            "7_kurt_x 0.6931471805599454\n",
            "7_max_x 0.6291634927060046\n",
            "7_min_x 0.6382572741742416\n",
            "7_dc_comp_x 0.6931471805599454\n",
            "7_spec_energy_x 0.6931471805599454\n",
            "7_max_psd_x 0.6931471805599454\n",
            "7_min_psd_x 0.6931471805599454\n",
            "7_min_max_psd_x 0.6931471805599454\n",
            "7_max_xas_x 0.6931471805599454\n",
            "7_min_xas_x 0.6931471805599454\n",
            "7_min_max_xas_x 0.6931471805599454\n",
            "7_mean_y 0.6931471805599454\n",
            "7_var_y 0.6931471805599454\n",
            "7_kurt_y 0.6931471805599454\n",
            "7_max_y 0.5333287934741094\n",
            "7_min_y 0.5129737736218022\n",
            "7_dc_comp_y 0.6931471805599454\n",
            "7_spec_energy_y 0.6931471805599454\n",
            "7_max_psd_y 0.6931471805599454\n",
            "7_min_psd_y 0.6931471805599454\n",
            "7_min_max_psd_y 0.6931471805599454\n",
            "7_max_xas_y 0.6931471805599454\n",
            "7_min_xas_y 0.6931471805599454\n",
            "7_min_max_xas_y 0.6931471805599454\n",
            "7_mean_z 0.6931471805599454\n",
            "7_var_z 0.6931471805599454\n",
            "7_kurt_z 0.6931471805599454\n",
            "7_max_z 0.6487781697609422\n",
            "7_min_z 0.6521219507168492\n",
            "7_dc_comp_z 0.6931471805599454\n",
            "7_spec_energy_z 0.6931471805599454\n",
            "7_max_psd_z 0.6931471805599454\n",
            "7_min_psd_z 0.6931471805599454\n",
            "7_min_max_psd_z 0.6931471805599454\n",
            "7_max_xas_z 0.6931471805599454\n",
            "7_min_xas_z 0.6931471805599454\n",
            "7_min_max_xas_z 0.6931471805599454\n",
            "7_mean_m 0.6931471805599454\n",
            "7_var_m 0.6931471805599454\n",
            "7_kurt_m 0.6931471805599454\n",
            "7_max_m 0.6931471805599454\n",
            "7_min_m 0.6931471805599454\n",
            "7_dc_comp_m 0.6931471805599454\n",
            "7_spec_energy_m 0.6931471805599454\n",
            "7_spec_entropy_m 0.6931471805599454\n",
            "7_max_psd_m 0.6931471805599454\n",
            "7_min_psd_m 0.6931471805599454\n",
            "7_min_max_psd_m 0.6931471805599454\n",
            "7_max_xas_m 0.6931471805599454\n",
            "7_min_xas_m 0.6931471805599454\n",
            "7_min_max_xas_m 0.6931471805599454\n",
            "8_mean_x 0.6931471805599454\n",
            "8_var_x 0.6931471805599454\n",
            "8_kurt_x 0.6931471805599454\n",
            "8_max_x 0.6560594578805672\n",
            "8_min_x 0.6472090429878933\n",
            "8_dc_comp_x 0.6931471805599454\n",
            "8_spec_energy_x 0.6931471805599454\n",
            "8_max_psd_x 0.6931471805599454\n",
            "8_min_psd_x 0.6931471805599454\n",
            "8_min_max_psd_x 0.6931471805599454\n",
            "8_max_xas_x 0.6931471805599454\n",
            "8_min_xas_x 0.6931471805599454\n",
            "8_min_max_xas_x 0.6931471805599454\n",
            "8_mean_y 0.6931471805599454\n",
            "8_var_y 0.6931471805599454\n",
            "8_kurt_y 0.6931471805599454\n",
            "8_max_y 0.614948456531149\n",
            "8_min_y 0.6226547474137953\n",
            "8_dc_comp_y 0.6931471805599454\n",
            "8_spec_energy_y 0.6931471805599454\n",
            "8_spec_entropy_y 0.6931471805599454\n",
            "8_max_psd_y 0.6931471805599454\n",
            "8_min_psd_y 0.6931471805599454\n",
            "8_min_max_psd_y 0.6931471805599454\n",
            "8_max_xas_y 0.6931471805599454\n",
            "8_min_xas_y 0.6931471805599454\n",
            "8_min_max_xas_y 0.6931471805599454\n",
            "8_mean_z 0.6931471805599454\n",
            "8_var_z 0.6931471805599454\n",
            "8_kurt_z 0.6931471805599454\n",
            "8_max_z 0.670509551823291\n",
            "8_min_z 0.6530281973911548\n",
            "8_dc_comp_z 0.6931471805599454\n",
            "8_spec_energy_z 0.6931471805599454\n",
            "8_spec_entropy_z 0.6931471805599454\n",
            "8_max_psd_z 0.6931471805599454\n",
            "8_min_psd_z 0.6931471805599454\n",
            "8_min_max_psd_z 0.6931471805599454\n",
            "8_max_xas_z 0.6931471805599454\n",
            "8_min_xas_z 0.6931471805599454\n",
            "8_min_max_xas_z 0.6931471805599454\n",
            "8_mean_m 0.6931471805599454\n",
            "8_var_m 0.6931471805599454\n",
            "8_kurt_m 0.6931471805599454\n",
            "8_max_m 0.6931471805599454\n",
            "8_min_m 0.6931471805599454\n",
            "8_dc_comp_m 0.6931471805599454\n",
            "8_spec_energy_m 0.6931471805599454\n",
            "8_spec_entropy_m 0.6931471805599454\n",
            "8_max_psd_m 0.6931471805599454\n",
            "8_min_psd_m 0.6931471805599454\n",
            "8_min_max_psd_m 0.6931471805599454\n",
            "8_max_xas_m 0.6931471805599454\n",
            "8_min_xas_m 0.6931471805599454\n",
            "8_min_max_xas_m 0.6931471805599454\n",
            "9_mean_x 0.6931471805599454\n",
            "9_var_x 0.6931471805599454\n",
            "9_kurt_x 0.6931471805599454\n",
            "9_max_x 0.6448194410468604\n",
            "9_min_x 0.6440468982194447\n",
            "9_dc_comp_x 0.6931471805599454\n",
            "9_spec_energy_x 0.6931471805599454\n",
            "9_spec_entropy_x 0.6931471805599454\n",
            "9_max_psd_x 0.6931471805599454\n",
            "9_min_psd_x 0.6931471805599454\n",
            "9_min_max_psd_x 0.6931471805599454\n",
            "9_max_xas_x 0.6931471805599454\n",
            "9_min_xas_x 0.6931471805599454\n",
            "9_min_max_xas_x 0.6931471805599454\n",
            "9_mean_y 0.6931471805599454\n",
            "9_var_y 0.6931471805599454\n",
            "9_kurt_y 0.6931471805599454\n",
            "9_max_y 0.5773658442060954\n",
            "9_min_y 0.5678697499259239\n",
            "9_dc_comp_y 0.6931471805599454\n",
            "9_spec_energy_y 0.6931471805599454\n",
            "9_spec_entropy_y 0.6931471805599454\n",
            "9_max_psd_y 0.6931471805599454\n",
            "9_min_psd_y 0.6931471805599454\n",
            "9_min_max_psd_y 0.6931471805599454\n",
            "9_max_xas_y 0.6931471805599454\n",
            "9_min_xas_y 0.6931471805599454\n",
            "9_min_max_xas_y 0.6931471805599454\n",
            "9_mean_z 0.6931471805599454\n",
            "9_var_z 0.6931471805599454\n",
            "9_kurt_z 0.6931471805599454\n",
            "9_max_z 0.6438652620319861\n",
            "9_min_z 0.6427635811226858\n",
            "9_dc_comp_z 0.6931471805599454\n",
            "9_spec_energy_z 0.6931471805599454\n",
            "9_max_psd_z 0.6931471805599454\n",
            "9_min_psd_z 0.6931471805599454\n",
            "9_min_max_psd_z 0.6931471805599454\n",
            "9_max_xas_z 0.6931471805599454\n",
            "9_min_xas_z 0.6931471805599454\n",
            "9_min_max_xas_z 0.6931471805599454\n",
            "9_mean_m 0.6931471805599454\n",
            "9_var_m 0.6931471805599454\n",
            "9_kurt_m 0.6931471805599454\n",
            "9_max_m 0.6931471805599454\n",
            "9_min_m 0.6931471805599454\n",
            "9_dc_comp_m 0.6931471805599454\n",
            "9_spec_energy_m 0.6931471805599454\n",
            "9_spec_entropy_m 0.6931471805599454\n",
            "9_max_psd_m 0.6931471805599454\n",
            "9_min_psd_m 0.6931471805599454\n",
            "9_min_max_psd_m 0.6931471805599454\n",
            "9_max_xas_m 0.6931471805599454\n",
            "9_min_xas_m 0.6931471805599454\n",
            "9_min_max_xas_m 0.6931471805599454\n",
            "8\n",
            "535\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(selected_feat_efs_mi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_bN1CL0pzir",
        "outputId": "beffe88b-ffbb-4289-dd9f-e43ca30682db"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "221"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DNN(nn.Module):\n",
        "    def __init__(self,input_size,output_size):\n",
        "        super(DNN,self).__init__()\n",
        "        self.hidden1 = nn.Linear(input_size,128)\n",
        "        self.hidden2 = nn.Linear(128,64)\n",
        "        self.hidden3 = nn.Linear(64,32)\n",
        "        self.output = nn.Linear(32,output_size)\n",
        "        self.softmax = F.softmax\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(p=0.2)\n",
        "        self.batchnorm1 = nn.BatchNorm1d(128)\n",
        "        self.batchnorm2 = nn.BatchNorm1d(64)\n",
        "        self.batchnorm3 = nn.BatchNorm1d(32)\n",
        "    \n",
        "    def forward(self,x):\n",
        "        out = self.hidden1(x)\n",
        "        out = self.batchnorm1(out)\n",
        "        out = self.relu(out)\n",
        "        \n",
        "        out = self.hidden2(out)\n",
        "        out = self.batchnorm2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.dropout(out)\n",
        "\n",
        "        out = self.hidden3(out)\n",
        "        out = self.batchnorm3(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.dropout(out)\n",
        "\n",
        "        out = self.output(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "9B_nzt6FHQCf"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_batch(X,y,batch_size,step,no_of_samples):\n",
        "  l = (step-1)*batch_size\n",
        "  return X[l:(l+batch_size)],y[l:min(no_of_samples,l+batch_size)]\n",
        "def multi_acc(y_pred, y_test):\n",
        "    y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n",
        "    _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)   \n",
        "    correct_pred = (y_pred_tags == y_test).float()\n",
        "    acc = correct_pred.sum()*1.0 / len(correct_pred)\n",
        "    acc = acc * 100\n",
        "    return acc"
      ],
      "metadata": {
        "id": "jIWh87J4HTgj"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_training_evaluation(X_train, X_test, X_val, y_train, y_test, y_val,selected_feat):\n",
        "  train_X = X_train[selected_feat]\n",
        "  test_X = X_test[selected_feat]\n",
        "  val_X = X_val[selected_feat]\n",
        "  scaler = MinMaxScaler()\n",
        "  train_X = scaler.fit_transform(train_X)\n",
        "  val_X = scaler.transform(val_X)\n",
        "  test_X = scaler.transform(test_X)\n",
        "  train_X = torch.from_numpy(train_X.astype(np.float32))\n",
        "  test_X = torch.from_numpy(test_X.astype(np.float32))\n",
        "  val_X = torch.from_numpy(val_X.astype(np.float32))\n",
        "  train_y =  torch.tensor(y_train.values.astype(np.float32))-1\n",
        "  test_y =  torch.tensor(y_test.values.astype(np.float32))-1\n",
        "  val_y =  torch.tensor(y_val.values.astype(np.float32))-1\n",
        "  input_size = train_X.shape[1]\n",
        "  output_size = torch.unique(train_y).shape[0]\n",
        "  learning_rate = 0.001\n",
        "  num_epochs = 1001\n",
        "  batch_size = 163\n",
        "  n_samples = train_X.shape[0]\n",
        "  criterion = nn.CrossEntropyLoss(reduction='sum')\n",
        "  best_lr = None\n",
        "  best_loss = 100000\n",
        "  best_model = None\n",
        "  best_train_loss = None\n",
        "  best_val_loss = None\n",
        "  for lr in [0.0005,0.001,0.003,0.005,0.01]:\n",
        "    #print(f\"Learning rate: {lr}:\")\n",
        "    net = DNN(input_size, output_size)\n",
        "    optimizer = torch.optim.SGD(net.parameters(), lr=lr)  \n",
        "    train_loss = []\n",
        "    val_loss = []\n",
        "    for epoch in range(num_epochs):\n",
        "      step = 1\n",
        "      while(batch_size*step<=n_samples):\n",
        "        x,y =  extract_batch(train_X,train_y, batch_size, step, n_samples)\n",
        "        # Forward Propagation\n",
        "        y_predicted = net(x)\n",
        "        loss = criterion(y_predicted,  torch.tensor(y, dtype=torch.long))\n",
        "        # Backward propagation and update\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # Performing zero grad before new step\n",
        "        optimizer.zero_grad()\n",
        "        step = step+1\n",
        "      train_loss.append(criterion( net(train_X),  torch.tensor(train_y, dtype=torch.long)).item()) \n",
        "      val_loss.append(criterion( net(val_X),  torch.tensor(val_y, dtype=torch.long)).item())\n",
        "      #appending the loss to the loss list\n",
        "      # if(epoch%100==0):\n",
        "      #   print(f'epoch: {epoch}, loss = {train_loss[-1]}')\n",
        "    val_ls = sum(val_loss)/len(val_loss)\n",
        "    if(val_ls<=best_loss):\n",
        "      best_loss = val_ls\n",
        "      best_lr = lr\n",
        "      best_model = net\n",
        "      best_val_loss = val_loss\n",
        "      best_train_loss = train_loss\n",
        "  #print(f\"Best_lr:{best_lr}\\nBest_loss:{best_loss}\")\n",
        "  y_pred = best_model(test_X)\n",
        "  acc = multi_acc(y_pred, test_y)\n",
        "  print(f\"Test accuracy is {(acc):.2f}%\")\n",
        "  sns.lineplot(range(1001),best_train_loss)\n",
        "  plt.ylabel(\"Total Loss\")\n",
        "  plt.xlabel(\"No of Epochs\")\n"
      ],
      "metadata": {
        "id": "IBf8MycHFgnS"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_training_evaluation(X_train, X_test, X_val, y_train, y_test, y_val,selected_feat_efs_mi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "apRE0QQqIA_E",
        "outputId": "e9c4e2f8-f2bf-49b1-ab75-965c31bd55ce"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy is 95.43%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_training_evaluation(X_train, X_test, X_val, y_train, y_test, y_val,selected_feat_ecfs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "RVDYyAbgIBRZ",
        "outputId": "430a1fc5-5a0d-436b-83f9-b593c5f2d2ca"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy is 96.86%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V00Nalj7NPcG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}