{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNa/wPiXWGSjTKmiDEs6otm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saadman53/Thesis-Human-Action-Recognition/blob/main/Human_Action_Recognition_using_Sensor_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3tTVmIJXdr_",
        "outputId": "a8a544c5-6489-4842-b7e7-33c1bfde8143"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "gdrive_path = \"drive/My Drive/Dataset/all_data.csv\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install minepy\n",
        "# !pip install info_gain\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "from minepy import MINE\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "import scipy\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.special import entr\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from scipy.stats import differential_entropy\n",
        "from scipy.stats import entropy\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwUL16kMXhyp",
        "outputId": "fe988b96-8578-43cc-dfc1-306c109658ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting minepy\n",
            "  Downloading minepy-1.2.6.tar.gz (496 kB)\n",
            "\u001b[K     |████████████████████████████████| 496 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from minepy) (1.21.6)\n",
            "Building wheels for collected packages: minepy\n",
            "  Building wheel for minepy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for minepy: filename=minepy-1.2.6-cp37-cp37m-linux_x86_64.whl size=177584 sha256=480df9d52e0416f322b4556bba7a454eed8b14242d53f84938ba51e0bfc0ab55\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/71/75/403a33428e468a25c93fa7b672d070b304f36642eb699a29e0\n",
            "Successfully built minepy\n",
            "Installing collected packages: minepy\n",
            "Successfully installed minepy-1.2.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(gdrive_path)\n",
        "df.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "1k6kAkaiXjLA",
        "outputId": "da088d00-3ea2-4591-e3d7-70bddc19cca0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0  0_mean_x   0_var_x   0_kurt_x   0_max_x   0_min_x  \\\n",
              "1160        1160 -0.054506  0.001862  -0.040152  0.072510 -0.149658   \n",
              "1161        1161 -0.026696  0.002853   5.849030  0.427002 -0.189697   \n",
              "1162        1162 -0.038772  0.001957  37.360906  0.555176 -0.434082   \n",
              "1163        1163 -0.084045  0.001579  -0.482562  0.028564 -0.166016   \n",
              "1164        1164 -0.043714  0.001209   0.021406  0.071533 -0.119873   \n",
              "\n",
              "      0_dc_comp_x  0_spec_energy_x  0_spec_entropy_x  0_max_psd_x  ...  \\\n",
              "1160  4178.914871     15331.889818          3.857213     0.420883  ...   \n",
              "1161   842.076824      1492.626785          5.105730     0.373887  ...   \n",
              "1162  1766.442641      2957.616036          6.873023     0.149166  ...   \n",
              "1163  9406.587377     77108.344139          3.375543     0.413470  ...   \n",
              "1164  1880.480207      3743.618849          3.326524     0.543291  ...   \n",
              "\n",
              "       9_dc_comp_m  9_spec_energy_m  9_spec_entropy_m  9_max_psd_m  \\\n",
              "1160  1.338846e+06     1.511391e+09          6.555544     0.113631   \n",
              "1161  1.131603e+06     1.178036e+09          6.289649     0.097086   \n",
              "1162  1.123454e+06     1.164343e+09          6.877409     0.068606   \n",
              "1163  1.274956e+06     1.408591e+09          6.892931     0.061177   \n",
              "1164  9.423824e+05     8.952466e+08          6.628678     0.059656   \n",
              "\n",
              "       9_min_psd_m  9_min_max_psd_m  9_max_xas_m  9_min_xas_m  \\\n",
              "1160  3.274603e-09     2.881788e-08     0.337092     0.000057   \n",
              "1161  1.527362e-08     1.573198e-07     0.311587     0.000124   \n",
              "1162  6.772243e-08     9.871164e-07     0.261928     0.000260   \n",
              "1163  1.379768e-08     2.255369e-07     0.247340     0.000117   \n",
              "1164  1.391945e-07     2.333289e-06     0.244246     0.000373   \n",
              "\n",
              "      9_min_max_xas_m  activity  \n",
              "1160         0.000170         9  \n",
              "1161         0.000397         9  \n",
              "1162         0.000994         9  \n",
              "1163         0.000475         9  \n",
              "1164         0.001528         9  \n",
              "\n",
              "[5 rows x 562 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7963c352-8d62-42e2-8183-acd52657125a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>0_mean_x</th>\n",
              "      <th>0_var_x</th>\n",
              "      <th>0_kurt_x</th>\n",
              "      <th>0_max_x</th>\n",
              "      <th>0_min_x</th>\n",
              "      <th>0_dc_comp_x</th>\n",
              "      <th>0_spec_energy_x</th>\n",
              "      <th>0_spec_entropy_x</th>\n",
              "      <th>0_max_psd_x</th>\n",
              "      <th>...</th>\n",
              "      <th>9_dc_comp_m</th>\n",
              "      <th>9_spec_energy_m</th>\n",
              "      <th>9_spec_entropy_m</th>\n",
              "      <th>9_max_psd_m</th>\n",
              "      <th>9_min_psd_m</th>\n",
              "      <th>9_min_max_psd_m</th>\n",
              "      <th>9_max_xas_m</th>\n",
              "      <th>9_min_xas_m</th>\n",
              "      <th>9_min_max_xas_m</th>\n",
              "      <th>activity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1160</th>\n",
              "      <td>1160</td>\n",
              "      <td>-0.054506</td>\n",
              "      <td>0.001862</td>\n",
              "      <td>-0.040152</td>\n",
              "      <td>0.072510</td>\n",
              "      <td>-0.149658</td>\n",
              "      <td>4178.914871</td>\n",
              "      <td>15331.889818</td>\n",
              "      <td>3.857213</td>\n",
              "      <td>0.420883</td>\n",
              "      <td>...</td>\n",
              "      <td>1.338846e+06</td>\n",
              "      <td>1.511391e+09</td>\n",
              "      <td>6.555544</td>\n",
              "      <td>0.113631</td>\n",
              "      <td>3.274603e-09</td>\n",
              "      <td>2.881788e-08</td>\n",
              "      <td>0.337092</td>\n",
              "      <td>0.000057</td>\n",
              "      <td>0.000170</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1161</th>\n",
              "      <td>1161</td>\n",
              "      <td>-0.026696</td>\n",
              "      <td>0.002853</td>\n",
              "      <td>5.849030</td>\n",
              "      <td>0.427002</td>\n",
              "      <td>-0.189697</td>\n",
              "      <td>842.076824</td>\n",
              "      <td>1492.626785</td>\n",
              "      <td>5.105730</td>\n",
              "      <td>0.373887</td>\n",
              "      <td>...</td>\n",
              "      <td>1.131603e+06</td>\n",
              "      <td>1.178036e+09</td>\n",
              "      <td>6.289649</td>\n",
              "      <td>0.097086</td>\n",
              "      <td>1.527362e-08</td>\n",
              "      <td>1.573198e-07</td>\n",
              "      <td>0.311587</td>\n",
              "      <td>0.000124</td>\n",
              "      <td>0.000397</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1162</th>\n",
              "      <td>1162</td>\n",
              "      <td>-0.038772</td>\n",
              "      <td>0.001957</td>\n",
              "      <td>37.360906</td>\n",
              "      <td>0.555176</td>\n",
              "      <td>-0.434082</td>\n",
              "      <td>1766.442641</td>\n",
              "      <td>2957.616036</td>\n",
              "      <td>6.873023</td>\n",
              "      <td>0.149166</td>\n",
              "      <td>...</td>\n",
              "      <td>1.123454e+06</td>\n",
              "      <td>1.164343e+09</td>\n",
              "      <td>6.877409</td>\n",
              "      <td>0.068606</td>\n",
              "      <td>6.772243e-08</td>\n",
              "      <td>9.871164e-07</td>\n",
              "      <td>0.261928</td>\n",
              "      <td>0.000260</td>\n",
              "      <td>0.000994</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1163</th>\n",
              "      <td>1163</td>\n",
              "      <td>-0.084045</td>\n",
              "      <td>0.001579</td>\n",
              "      <td>-0.482562</td>\n",
              "      <td>0.028564</td>\n",
              "      <td>-0.166016</td>\n",
              "      <td>9406.587377</td>\n",
              "      <td>77108.344139</td>\n",
              "      <td>3.375543</td>\n",
              "      <td>0.413470</td>\n",
              "      <td>...</td>\n",
              "      <td>1.274956e+06</td>\n",
              "      <td>1.408591e+09</td>\n",
              "      <td>6.892931</td>\n",
              "      <td>0.061177</td>\n",
              "      <td>1.379768e-08</td>\n",
              "      <td>2.255369e-07</td>\n",
              "      <td>0.247340</td>\n",
              "      <td>0.000117</td>\n",
              "      <td>0.000475</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1164</th>\n",
              "      <td>1164</td>\n",
              "      <td>-0.043714</td>\n",
              "      <td>0.001209</td>\n",
              "      <td>0.021406</td>\n",
              "      <td>0.071533</td>\n",
              "      <td>-0.119873</td>\n",
              "      <td>1880.480207</td>\n",
              "      <td>3743.618849</td>\n",
              "      <td>3.326524</td>\n",
              "      <td>0.543291</td>\n",
              "      <td>...</td>\n",
              "      <td>9.423824e+05</td>\n",
              "      <td>8.952466e+08</td>\n",
              "      <td>6.628678</td>\n",
              "      <td>0.059656</td>\n",
              "      <td>1.391945e-07</td>\n",
              "      <td>2.333289e-06</td>\n",
              "      <td>0.244246</td>\n",
              "      <td>0.000373</td>\n",
              "      <td>0.001528</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 562 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7963c352-8d62-42e2-8183-acd52657125a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7963c352-8d62-42e2-8183-acd52657125a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7963c352-8d62-42e2-8183-acd52657125a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(df.columns[df.isna().any()].tolist(), axis = 1, inplace = True)\n",
        "df.drop(['Unnamed: 0'], axis = 1, inplace = True)"
      ],
      "metadata": {
        "id": "pbCKNbRtXni2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##symmetrical uncertainty\n",
        "def SU(df, X,Y):\n",
        "  if(Y=='activity'):\n",
        "    IG = mutual_info_classif(np.transpose(np.array([df[X]])), df[Y]).item()\n",
        "    H_Y = entropy(df[Y])\n",
        "  else:\n",
        "    IG = mutual_info_regression(np.transpose(np.array([df[X]])), df[Y]).item()\n",
        "    H_Y = differential_entropy(df[Y])\n",
        "  H_X = differential_entropy(df[X])\n",
        "  su = ((2.0*IG)/(H_X+H_Y))\n",
        "  #print(IG,H_X,H_Y, su)\n",
        "  return su\n",
        "  \n",
        "#Fast Correlation Based Filter\n",
        "def FCBF(df, features, C):\n",
        "  thresh = 0.000001\n",
        "  N = len(features)\n",
        "  S_list = {}\n",
        "  for i in range(N):\n",
        "    val = SU(df, features[i], C)\n",
        "    if(val> thresh):\n",
        "      S_list[features[i]] = val\n",
        "  S_list = pd.Series(S_list).sort_values(ascending=False)\n",
        "  no_features = S_list.shape[0]\n",
        "  a_list = np.ones(no_features)\n",
        "  for i in range(no_features):\n",
        "    if(a_list[i]==1):\n",
        "      Fp = S_list.index[i]\n",
        "      for j in range(i+1,no_features):\n",
        "        if(a_list[j]==1):\n",
        "          Fq = S_list.index[j]\n",
        "          if(SU(df, Fp,Fq) >= S_list[j]):\n",
        "            print(f\"{j} has been eleminated while in {i}\")\n",
        "            a_list[j]=0\n",
        "  idx = np.where(a_list==1)[0]\n",
        "  return S_list.index[idx]"
      ],
      "metadata": {
        "id": "3_Y3f2i4XwW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = list(df.columns[:-1])\n",
        "C = 'activity'\n",
        "selected_features = FCBF(df, features, C)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuG7-CWgqwLt",
        "outputId": "90278669-94ca-4f63-f946-2230d9845df6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "344 has been eleminated while in 0\n",
            "362 has been eleminated while in 0\n",
            "370 has been eleminated while in 0\n",
            "375 has been eleminated while in 0\n",
            "380 has been eleminated while in 0\n",
            "382 has been eleminated while in 1\n",
            "372 has been eleminated while in 2\n",
            "377 has been eleminated while in 2\n",
            "374 has been eleminated while in 3\n",
            "366 has been eleminated while in 4\n",
            "368 has been eleminated while in 4\n",
            "371 has been eleminated while in 4\n",
            "376 has been eleminated while in 4\n",
            "381 has been eleminated while in 12\n",
            "355 has been eleminated while in 17\n",
            "226 has been eleminated while in 22\n",
            "234 has been eleminated while in 22\n",
            "277 has been eleminated while in 22\n",
            "319 has been eleminated while in 22\n",
            "320 has been eleminated while in 22\n",
            "245 has been eleminated while in 24\n",
            "324 has been eleminated while in 24\n",
            "267 has been eleminated while in 27\n",
            "284 has been eleminated while in 27\n",
            "287 has been eleminated while in 27\n",
            "288 has been eleminated while in 27\n",
            "294 has been eleminated while in 27\n",
            "301 has been eleminated while in 27\n",
            "317 has been eleminated while in 27\n",
            "335 has been eleminated while in 27\n",
            "340 has been eleminated while in 27\n",
            "341 has been eleminated while in 27\n",
            "342 has been eleminated while in 27\n",
            "353 has been eleminated while in 27\n",
            "356 has been eleminated while in 27\n",
            "357 has been eleminated while in 27\n",
            "351 has been eleminated while in 28\n",
            "360 has been eleminated while in 28\n",
            "96 has been eleminated while in 32\n",
            "111 has been eleminated while in 32\n",
            "128 has been eleminated while in 32\n",
            "131 has been eleminated while in 32\n",
            "150 has been eleminated while in 32\n",
            "151 has been eleminated while in 32\n",
            "156 has been eleminated while in 32\n",
            "217 has been eleminated while in 32\n",
            "260 has been eleminated while in 32\n",
            "289 has been eleminated while in 32\n",
            "307 has been eleminated while in 32\n",
            "326 has been eleminated while in 32\n",
            "330 has been eleminated while in 32\n",
            "347 has been eleminated while in 32\n",
            "348 has been eleminated while in 32\n",
            "321 has been eleminated while in 34\n",
            "42 has been eleminated while in 41\n",
            "45 has been eleminated while in 41\n",
            "48 has been eleminated while in 41\n",
            "59 has been eleminated while in 41\n",
            "61 has been eleminated while in 41\n",
            "67 has been eleminated while in 41\n",
            "68 has been eleminated while in 41\n",
            "72 has been eleminated while in 41\n",
            "74 has been eleminated while in 41\n",
            "76 has been eleminated while in 41\n",
            "79 has been eleminated while in 41\n",
            "80 has been eleminated while in 41\n",
            "81 has been eleminated while in 41\n",
            "88 has been eleminated while in 41\n",
            "90 has been eleminated while in 41\n",
            "94 has been eleminated while in 41\n",
            "103 has been eleminated while in 41\n",
            "108 has been eleminated while in 41\n",
            "112 has been eleminated while in 41\n",
            "114 has been eleminated while in 41\n",
            "119 has been eleminated while in 41\n",
            "139 has been eleminated while in 41\n",
            "147 has been eleminated while in 41\n",
            "154 has been eleminated while in 41\n",
            "180 has been eleminated while in 41\n",
            "189 has been eleminated while in 41\n",
            "195 has been eleminated while in 41\n",
            "197 has been eleminated while in 41\n",
            "198 has been eleminated while in 41\n",
            "201 has been eleminated while in 41\n",
            "204 has been eleminated while in 41\n",
            "215 has been eleminated while in 41\n",
            "218 has been eleminated while in 41\n",
            "222 has been eleminated while in 41\n",
            "224 has been eleminated while in 41\n",
            "225 has been eleminated while in 41\n",
            "241 has been eleminated while in 41\n",
            "250 has been eleminated while in 41\n",
            "270 has been eleminated while in 41\n",
            "275 has been eleminated while in 41\n",
            "279 has been eleminated while in 41\n",
            "303 has been eleminated while in 41\n",
            "318 has been eleminated while in 41\n",
            "332 has been eleminated while in 41\n",
            "334 has been eleminated while in 41\n",
            "343 has been eleminated while in 41\n",
            "345 has been eleminated while in 41\n",
            "346 has been eleminated while in 41\n",
            "349 has been eleminated while in 41\n",
            "350 has been eleminated while in 41\n",
            "352 has been eleminated while in 41\n",
            "354 has been eleminated while in 41\n",
            "358 has been eleminated while in 41\n",
            "364 has been eleminated while in 41\n",
            "367 has been eleminated while in 41\n",
            "253 has been eleminated while in 43\n",
            "286 has been eleminated while in 43\n",
            "327 has been eleminated while in 43\n",
            "365 has been eleminated while in 43\n",
            "240 has been eleminated while in 47\n",
            "379 has been eleminated while in 47\n",
            "369 has been eleminated while in 49\n",
            "378 has been eleminated while in 49\n",
            "152 has been eleminated while in 52\n",
            "214 has been eleminated while in 52\n",
            "261 has been eleminated while in 52\n",
            "280 has been eleminated while in 56\n",
            "373 has been eleminated while in 85\n",
            "363 has been eleminated while in 101\n",
            "295 has been eleminated while in 130\n",
            "312 has been eleminated while in 134\n",
            "243 has been eleminated while in 235\n",
            "244 has been eleminated while in 235\n",
            "246 has been eleminated while in 235\n",
            "249 has been eleminated while in 235\n",
            "252 has been eleminated while in 235\n",
            "255 has been eleminated while in 235\n",
            "257 has been eleminated while in 235\n",
            "259 has been eleminated while in 235\n",
            "262 has been eleminated while in 235\n",
            "264 has been eleminated while in 235\n",
            "265 has been eleminated while in 235\n",
            "269 has been eleminated while in 235\n",
            "272 has been eleminated while in 235\n",
            "278 has been eleminated while in 235\n",
            "281 has been eleminated while in 235\n",
            "293 has been eleminated while in 235\n",
            "296 has been eleminated while in 235\n",
            "299 has been eleminated while in 235\n",
            "300 has been eleminated while in 235\n",
            "302 has been eleminated while in 235\n",
            "304 has been eleminated while in 235\n",
            "305 has been eleminated while in 235\n",
            "306 has been eleminated while in 235\n",
            "309 has been eleminated while in 235\n",
            "310 has been eleminated while in 235\n",
            "311 has been eleminated while in 235\n",
            "313 has been eleminated while in 235\n",
            "315 has been eleminated while in 235\n",
            "322 has been eleminated while in 235\n",
            "331 has been eleminated while in 235\n",
            "336 has been eleminated while in 235\n",
            "339 has been eleminated while in 274\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "df[selected_features] = scaler.fit_transform(df[selected_features])\n",
        "X = df[selected_features]\n",
        "y = df['activity']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.3, random_state=42)\n",
        "\n",
        "X_train = torch.from_numpy(X_train.to_numpy().astype(np.float32))\n",
        "X_test = torch.from_numpy(X_test.to_numpy().astype(np.float32))\n",
        "y_train =  torch.tensor(y_train.values.astype(np.float32))-1\n",
        "y_test =  torch.tensor(y_test.values.astype(np.float32))-1"
      ],
      "metadata": {
        "id": "77UPtOS7X1zh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ANN(nn.Module):\n",
        "    def __init__(self,input_size,output_size):\n",
        "        super(ANN,self).__init__()\n",
        "        self.hidden1 = nn.Linear(input_size,128)\n",
        "        self.hidden2 = nn.Linear(128,64)\n",
        "        self.hidden3 = nn.Linear(64,32)\n",
        "        self.output = nn.Linear(32,output_size)\n",
        "        self.softmax = F.softmax\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(p=0.2)\n",
        "        self.batchnorm1 = nn.BatchNorm1d(128)\n",
        "        self.batchnorm2 = nn.BatchNorm1d(64)\n",
        "        self.batchnorm3 = nn.BatchNorm1d(32)\n",
        "    \n",
        "    def forward(self,x):\n",
        "        out = self.hidden1(x)\n",
        "        out = self.batchnorm1(out)\n",
        "        out = self.relu(out)\n",
        "        \n",
        "        out = self.hidden2(out)\n",
        "        out = self.batchnorm2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.dropout(out)\n",
        "\n",
        "        out = self.hidden3(out)\n",
        "        out = self.batchnorm3(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.dropout(out)\n",
        "\n",
        "        out = self.output(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "fnn0yDuHX7nH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = X_train.shape[1]\n",
        "output_size = torch.unique(y_train).shape[0]\n",
        "learning_rate = 0.001\n",
        "num_epochs = 1001\n",
        "batch_size = 163\n",
        "no_of_samples = X_train.shape[0]"
      ],
      "metadata": {
        "id": "IXXVqyhhX-vh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss(reduction='sum')"
      ],
      "metadata": {
        "id": "R55egUmIYBDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_batch(X,y,batch_size,step):\n",
        "  l = (step-1)*batch_size\n",
        "  return X[l:(l+batch_size)],y[l:min(no_of_samples,l+batch_size)]"
      ],
      "metadata": {
        "id": "TMx87EXTYEnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_lr = None\n",
        "best_loss = 100000\n",
        "best_model = None\n",
        "best_train_loss = None\n",
        "for lr in [0.0005,0.001,0.003,0.005,0.01]:\n",
        "  print(f\"Learning rate: {lr}:\")\n",
        "  net = ANN(input_size, output_size)\n",
        "  optimizer = torch.optim.SGD(net.parameters(), lr=lr)  \n",
        "  train_loss = []\n",
        "  for epoch in range(num_epochs):\n",
        "    step = 1\n",
        "    while(batch_size*step<=no_of_samples):\n",
        "      x,y =  extract_batch(X_train,y_train, batch_size, step)\n",
        "      # Forward Propagation\n",
        "      y_predicted = net(x)\n",
        "      loss = criterion(y_predicted,  torch.tensor(y, dtype=torch.long))\n",
        "      #loss = cross_entropy(y_predicted,y)\n",
        "      # Backward propagation and update\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      # Performing zero grad before new step\n",
        "      optimizer.zero_grad()\n",
        "      step = step+1\n",
        "    train_loss.append(criterion( net(X_train),  torch.tensor(y_train, dtype=torch.long)).item()) \n",
        "      #appending the loss to the loss list\n",
        "    if(epoch%100==0):\n",
        "      print(f'epoch: {epoch}, loss = {train_loss[-1]}')\n",
        "  if(train_loss[-1]<=best_loss):\n",
        "    best_loss = train_loss[-1]\n",
        "    best_lr = lr\n",
        "    best_model = net\n",
        "    best_train_loss = train_loss\n",
        "print(f\"Best_lr:{best_lr}\\nBest_loss:{best_loss}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jKgwWbDYF5H",
        "outputId": "8cadb9ee-8c3e-47c2-edc4-e942bf268548"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate: 0.0005:\n",
            "epoch: 0, loss = 2116.648681640625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 100, loss = 67.49040222167969\n",
            "epoch: 200, loss = 29.46388816833496\n",
            "epoch: 300, loss = 20.94906234741211\n",
            "epoch: 400, loss = 20.607646942138672\n",
            "epoch: 500, loss = 9.627558708190918\n",
            "epoch: 600, loss = 14.452988624572754\n",
            "epoch: 700, loss = 7.88195276260376\n",
            "epoch: 800, loss = 10.223644256591797\n",
            "epoch: 900, loss = 11.098575592041016\n",
            "epoch: 1000, loss = 7.954860687255859\n",
            "Learning rate: 0.001:\n",
            "epoch: 0, loss = 1952.1739501953125\n",
            "epoch: 100, loss = 34.93665313720703\n",
            "epoch: 200, loss = 18.651456832885742\n",
            "epoch: 300, loss = 14.303513526916504\n",
            "epoch: 400, loss = 8.27188777923584\n",
            "epoch: 500, loss = 7.292801856994629\n",
            "epoch: 600, loss = 5.4057536125183105\n",
            "epoch: 700, loss = 5.34654426574707\n",
            "epoch: 800, loss = 4.090232849121094\n",
            "epoch: 900, loss = 7.083451747894287\n",
            "epoch: 1000, loss = 8.153142929077148\n",
            "Learning rate: 0.003:\n",
            "epoch: 0, loss = 1559.026611328125\n",
            "epoch: 100, loss = 12.341840744018555\n",
            "epoch: 200, loss = 6.009915351867676\n",
            "epoch: 300, loss = 7.114253044128418\n",
            "epoch: 400, loss = 4.256752967834473\n",
            "epoch: 500, loss = 4.136090278625488\n",
            "epoch: 600, loss = 4.648421287536621\n",
            "epoch: 700, loss = 2.1869664192199707\n",
            "epoch: 800, loss = 1.1794140338897705\n",
            "epoch: 900, loss = 2.9826395511627197\n",
            "epoch: 1000, loss = 2.7820897102355957\n",
            "Learning rate: 0.005:\n",
            "epoch: 0, loss = 1384.8243408203125\n",
            "epoch: 100, loss = 8.852499008178711\n",
            "epoch: 200, loss = 8.486421585083008\n",
            "epoch: 300, loss = 6.873305320739746\n",
            "epoch: 400, loss = 3.214057445526123\n",
            "epoch: 500, loss = 2.1520373821258545\n",
            "epoch: 600, loss = 1.9692689180374146\n",
            "epoch: 700, loss = 4.370628833770752\n",
            "epoch: 800, loss = 2.013274669647217\n",
            "epoch: 900, loss = 3.2553930282592773\n",
            "epoch: 1000, loss = 3.109633207321167\n",
            "Learning rate: 0.01:\n",
            "epoch: 0, loss = 1310.665771484375\n",
            "epoch: 100, loss = 6.2348175048828125\n",
            "epoch: 200, loss = 3.720715284347534\n",
            "epoch: 300, loss = 6.042788982391357\n",
            "epoch: 400, loss = 5.192298889160156\n",
            "epoch: 500, loss = 1.3421846628189087\n",
            "epoch: 600, loss = 3.8477602005004883\n",
            "epoch: 700, loss = 2.3143858909606934\n",
            "epoch: 800, loss = 1.2393463850021362\n",
            "epoch: 900, loss = 1.116366982460022\n",
            "epoch: 1000, loss = 1.2102375030517578\n",
            "Best_lr:0.01\n",
            "Best_loss:1.2102375030517578\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def multi_acc(y_pred, y_test):\n",
        "    y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n",
        "    _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)   \n",
        "    correct_pred = (y_pred_tags == y_test).float()\n",
        "    acc = correct_pred.sum()*1.0 / len(correct_pred)\n",
        "    acc = acc * 100\n",
        "    return acc"
      ],
      "metadata": {
        "id": "QeLV165gYHnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = best_model(X_test)\n",
        "acc = multi_acc(y_pred, y_test)\n",
        "print(f\"Test accuracy is {(acc):.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lj9jd9CtYI_T",
        "outputId": "d3566612-b682-419c-9584-923ad1b9c130"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy is 97.71%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "sns.lineplot(range(1001),best_train_loss)\n",
        "plt.xlabel(\"Total Loss\")\n",
        "plt.ylabel(\"No of Epochs\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "jziLsqKydAkd",
        "outputId": "44349d10-5e11-4875-f2c2-53ef8bfc118b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'No of Epochs')"
            ]
          },
          "metadata": {},
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BXVvOPG3tIT3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}