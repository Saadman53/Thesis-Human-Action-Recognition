{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPYlOwFu1AxTL9qBOf9bfU6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saadman53/Thesis-Human-Action-Recognition/blob/main/Human_Action_Recognition_using_Sensor_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3tTVmIJXdr_",
        "outputId": "fd7b108f-ac0f-40ef-e92d-919069c7a081"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "gdrive_path = \"drive/My Drive/Dataset/all_data.csv\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install minepy\n",
        "!pip install sklearn_relief\n",
        "!pip install sklearn-genetic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvsFKxx7oZ3a",
        "outputId": "1e6ed023-57a5-47c2-82cd-b01d3ed823d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting minepy\n",
            "  Downloading minepy-1.2.6.tar.gz (496 kB)\n",
            "\u001b[K     |████████████████████████████████| 496 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from minepy) (1.21.6)\n",
            "Building wheels for collected packages: minepy\n",
            "  Building wheel for minepy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for minepy: filename=minepy-1.2.6-cp37-cp37m-linux_x86_64.whl size=177577 sha256=fac1cca3ddbc092261b21210142a392ac6e7d853d46bdd070f73dc0ba8d82614\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/71/75/403a33428e468a25c93fa7b672d070b304f36642eb699a29e0\n",
            "Successfully built minepy\n",
            "Installing collected packages: minepy\n",
            "Successfully installed minepy-1.2.6\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sklearn_relief\n",
            "  Downloading sklearn_relief-1.0.0b2-py3-none-any.whl (8.7 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from sklearn_relief) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from sklearn_relief) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from sklearn_relief) (1.21.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->sklearn_relief) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->sklearn_relief) (1.2.0)\n",
            "Installing collected packages: sklearn-relief\n",
            "Successfully installed sklearn-relief-1.0.0b2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sklearn-genetic\n",
            "  Downloading sklearn_genetic-0.5.1-py3-none-any.whl (11 kB)\n",
            "Collecting deap>=1.0.2\n",
            "  Downloading deap-1.3.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (139 kB)\n",
            "\u001b[K     |████████████████████████████████| 139 kB 4.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.23 in /usr/local/lib/python3.7/dist-packages (from sklearn-genetic) (1.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sklearn-genetic) (1.21.6)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py37-none-any.whl (115 kB)\n",
            "\u001b[K     |████████████████████████████████| 115 kB 51.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.23->sklearn-genetic) (1.7.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.23->sklearn-genetic) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.23->sklearn-genetic) (1.2.0)\n",
            "Requirement already satisfied: dill>=0.3.6 in /usr/local/lib/python3.7/dist-packages (from multiprocess->sklearn-genetic) (0.3.6)\n",
            "Installing collected packages: multiprocess, deap, sklearn-genetic\n",
            "Successfully installed deap-1.3.3 multiprocess-0.70.14 sklearn-genetic-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "from minepy import MINE\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "import scipy\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.special import entr\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from scipy.stats import differential_entropy\n",
        "from scipy.stats import entropy\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "from genetic_selection import GeneticSelectionCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from sklearn.feature_selection import mutual_info_regression"
      ],
      "metadata": {
        "id": "QwUL16kMXhyp"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(gdrive_path)\n",
        "df.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "1k6kAkaiXjLA",
        "outputId": "0235f906-eb97-4ad6-c426-ba2ee2610f6a"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0  0_mean_x   0_var_x   0_kurt_x   0_max_x   0_min_x  \\\n",
              "1160        1160 -0.054506  0.001862  -0.040152  0.072510 -0.149658   \n",
              "1161        1161 -0.026696  0.002853   5.849030  0.427002 -0.189697   \n",
              "1162        1162 -0.038772  0.001957  37.360906  0.555176 -0.434082   \n",
              "1163        1163 -0.084045  0.001579  -0.482562  0.028564 -0.166016   \n",
              "1164        1164 -0.043714  0.001209   0.021406  0.071533 -0.119873   \n",
              "\n",
              "      0_dc_comp_x  0_spec_energy_x  0_spec_entropy_x  0_max_psd_x  ...  \\\n",
              "1160  4178.914871     15331.889818          3.857213     0.420883  ...   \n",
              "1161   842.076824      1492.626785          5.105730     0.373887  ...   \n",
              "1162  1766.442641      2957.616036          6.873023     0.149166  ...   \n",
              "1163  9406.587377     77108.344139          3.375543     0.413470  ...   \n",
              "1164  1880.480207      3743.618849          3.326524     0.543291  ...   \n",
              "\n",
              "       9_dc_comp_m  9_spec_energy_m  9_spec_entropy_m  9_max_psd_m  \\\n",
              "1160  1.338846e+06     1.511391e+09          6.555544     0.113631   \n",
              "1161  1.131603e+06     1.178036e+09          6.289649     0.097086   \n",
              "1162  1.123454e+06     1.164343e+09          6.877409     0.068606   \n",
              "1163  1.274956e+06     1.408591e+09          6.892931     0.061177   \n",
              "1164  9.423824e+05     8.952466e+08          6.628678     0.059656   \n",
              "\n",
              "       9_min_psd_m  9_min_max_psd_m  9_max_xas_m  9_min_xas_m  \\\n",
              "1160  3.274603e-09     2.881788e-08     0.337092     0.000057   \n",
              "1161  1.527362e-08     1.573198e-07     0.311587     0.000124   \n",
              "1162  6.772243e-08     9.871164e-07     0.261928     0.000260   \n",
              "1163  1.379768e-08     2.255369e-07     0.247340     0.000117   \n",
              "1164  1.391945e-07     2.333289e-06     0.244246     0.000373   \n",
              "\n",
              "      9_min_max_xas_m  activity  \n",
              "1160         0.000170         9  \n",
              "1161         0.000397         9  \n",
              "1162         0.000994         9  \n",
              "1163         0.000475         9  \n",
              "1164         0.001528         9  \n",
              "\n",
              "[5 rows x 562 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2adfd9ab-9afc-4f74-bf0e-90d33b8917a2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>0_mean_x</th>\n",
              "      <th>0_var_x</th>\n",
              "      <th>0_kurt_x</th>\n",
              "      <th>0_max_x</th>\n",
              "      <th>0_min_x</th>\n",
              "      <th>0_dc_comp_x</th>\n",
              "      <th>0_spec_energy_x</th>\n",
              "      <th>0_spec_entropy_x</th>\n",
              "      <th>0_max_psd_x</th>\n",
              "      <th>...</th>\n",
              "      <th>9_dc_comp_m</th>\n",
              "      <th>9_spec_energy_m</th>\n",
              "      <th>9_spec_entropy_m</th>\n",
              "      <th>9_max_psd_m</th>\n",
              "      <th>9_min_psd_m</th>\n",
              "      <th>9_min_max_psd_m</th>\n",
              "      <th>9_max_xas_m</th>\n",
              "      <th>9_min_xas_m</th>\n",
              "      <th>9_min_max_xas_m</th>\n",
              "      <th>activity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1160</th>\n",
              "      <td>1160</td>\n",
              "      <td>-0.054506</td>\n",
              "      <td>0.001862</td>\n",
              "      <td>-0.040152</td>\n",
              "      <td>0.072510</td>\n",
              "      <td>-0.149658</td>\n",
              "      <td>4178.914871</td>\n",
              "      <td>15331.889818</td>\n",
              "      <td>3.857213</td>\n",
              "      <td>0.420883</td>\n",
              "      <td>...</td>\n",
              "      <td>1.338846e+06</td>\n",
              "      <td>1.511391e+09</td>\n",
              "      <td>6.555544</td>\n",
              "      <td>0.113631</td>\n",
              "      <td>3.274603e-09</td>\n",
              "      <td>2.881788e-08</td>\n",
              "      <td>0.337092</td>\n",
              "      <td>0.000057</td>\n",
              "      <td>0.000170</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1161</th>\n",
              "      <td>1161</td>\n",
              "      <td>-0.026696</td>\n",
              "      <td>0.002853</td>\n",
              "      <td>5.849030</td>\n",
              "      <td>0.427002</td>\n",
              "      <td>-0.189697</td>\n",
              "      <td>842.076824</td>\n",
              "      <td>1492.626785</td>\n",
              "      <td>5.105730</td>\n",
              "      <td>0.373887</td>\n",
              "      <td>...</td>\n",
              "      <td>1.131603e+06</td>\n",
              "      <td>1.178036e+09</td>\n",
              "      <td>6.289649</td>\n",
              "      <td>0.097086</td>\n",
              "      <td>1.527362e-08</td>\n",
              "      <td>1.573198e-07</td>\n",
              "      <td>0.311587</td>\n",
              "      <td>0.000124</td>\n",
              "      <td>0.000397</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1162</th>\n",
              "      <td>1162</td>\n",
              "      <td>-0.038772</td>\n",
              "      <td>0.001957</td>\n",
              "      <td>37.360906</td>\n",
              "      <td>0.555176</td>\n",
              "      <td>-0.434082</td>\n",
              "      <td>1766.442641</td>\n",
              "      <td>2957.616036</td>\n",
              "      <td>6.873023</td>\n",
              "      <td>0.149166</td>\n",
              "      <td>...</td>\n",
              "      <td>1.123454e+06</td>\n",
              "      <td>1.164343e+09</td>\n",
              "      <td>6.877409</td>\n",
              "      <td>0.068606</td>\n",
              "      <td>6.772243e-08</td>\n",
              "      <td>9.871164e-07</td>\n",
              "      <td>0.261928</td>\n",
              "      <td>0.000260</td>\n",
              "      <td>0.000994</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1163</th>\n",
              "      <td>1163</td>\n",
              "      <td>-0.084045</td>\n",
              "      <td>0.001579</td>\n",
              "      <td>-0.482562</td>\n",
              "      <td>0.028564</td>\n",
              "      <td>-0.166016</td>\n",
              "      <td>9406.587377</td>\n",
              "      <td>77108.344139</td>\n",
              "      <td>3.375543</td>\n",
              "      <td>0.413470</td>\n",
              "      <td>...</td>\n",
              "      <td>1.274956e+06</td>\n",
              "      <td>1.408591e+09</td>\n",
              "      <td>6.892931</td>\n",
              "      <td>0.061177</td>\n",
              "      <td>1.379768e-08</td>\n",
              "      <td>2.255369e-07</td>\n",
              "      <td>0.247340</td>\n",
              "      <td>0.000117</td>\n",
              "      <td>0.000475</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1164</th>\n",
              "      <td>1164</td>\n",
              "      <td>-0.043714</td>\n",
              "      <td>0.001209</td>\n",
              "      <td>0.021406</td>\n",
              "      <td>0.071533</td>\n",
              "      <td>-0.119873</td>\n",
              "      <td>1880.480207</td>\n",
              "      <td>3743.618849</td>\n",
              "      <td>3.326524</td>\n",
              "      <td>0.543291</td>\n",
              "      <td>...</td>\n",
              "      <td>9.423824e+05</td>\n",
              "      <td>8.952466e+08</td>\n",
              "      <td>6.628678</td>\n",
              "      <td>0.059656</td>\n",
              "      <td>1.391945e-07</td>\n",
              "      <td>2.333289e-06</td>\n",
              "      <td>0.244246</td>\n",
              "      <td>0.000373</td>\n",
              "      <td>0.001528</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 562 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2adfd9ab-9afc-4f74-bf0e-90d33b8917a2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2adfd9ab-9afc-4f74-bf0e-90d33b8917a2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2adfd9ab-9afc-4f74-bf0e-90d33b8917a2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(df.columns[df.isna().any()].tolist(), axis = 1, inplace = True)\n",
        "df.drop(['Unnamed: 0'], axis = 1, inplace = True)"
      ],
      "metadata": {
        "id": "pbCKNbRtXni2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(['activity'], axis = 1)\n",
        "y = df['activity']\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y,test_size=0.3, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val,test_size=0.1, random_state=21)"
      ],
      "metadata": {
        "id": "Qy2_4uGbNGD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#relief f\n",
        "from sklearn.metrics.pairwise import pairwise_distances\n",
        "def reliefF(X, y, **kwargs):\n",
        "    \"\"\"\n",
        "    This function implements the reliefF feature selection\n",
        "    Input\n",
        "    -----\n",
        "    X: {numpy array}, shape (n_samples, n_features)\n",
        "        input data\n",
        "    y: {numpy array}, shape (n_samples,)\n",
        "        input class labels\n",
        "    kwargs: {dictionary}\n",
        "        parameters of reliefF:\n",
        "        k: {int}\n",
        "            choices for the number of neighbors (default k = 5)\n",
        "    Output\n",
        "    ------\n",
        "    score: {numpy array}, shape (n_features,)\n",
        "        reliefF score for each feature\n",
        "    Reference\n",
        "    ---------\n",
        "    Robnik-Sikonja, Marko et al. \"Theoretical and empirical analysis of relieff and rrelieff.\" Machine Learning 2003.\n",
        "    Zhao, Zheng et al. \"On Similarity Preserving Feature Selection.\" TKDE 2013.\n",
        "    \"\"\"\n",
        "\n",
        "    if \"k\" not in kwargs.keys():\n",
        "        k = 5\n",
        "    else:\n",
        "        k = kwargs[\"k\"]\n",
        "    n_samples, n_features = X.shape\n",
        "\n",
        "    # calculate pairwise distances between instances\n",
        "    distance = pairwise_distances(X, metric='manhattan')\n",
        "\n",
        "    score = np.zeros(n_features)\n",
        "\n",
        "    # the number of sampled instances is equal to the number of total instances\n",
        "    for idx in range(n_samples):\n",
        "        near_hit = []\n",
        "        near_miss = dict()\n",
        "\n",
        "        self_fea = X[idx, :]\n",
        "        c = np.unique(y).tolist()\n",
        "\n",
        "        stop_dict = dict()\n",
        "        for label in c:\n",
        "            stop_dict[label] = 0\n",
        "        del c[c.index(y[idx])]\n",
        "\n",
        "        p_dict = dict()\n",
        "        p_label_idx = float(len(y[y == y[idx]]))/float(n_samples)\n",
        "\n",
        "        for label in c:\n",
        "            p_label_c = float(len(y[y == label]))/float(n_samples)\n",
        "            p_dict[label] = p_label_c/(1-p_label_idx)\n",
        "            near_miss[label] = []\n",
        "\n",
        "        distance_sort = []\n",
        "        distance[idx, idx] = np.max(distance[idx, :])\n",
        "\n",
        "        for i in range(n_samples):\n",
        "            distance_sort.append([distance[idx, i], int(i), y[i]])\n",
        "        distance_sort.sort(key=lambda x: x[0])\n",
        "\n",
        "        for i in range(n_samples):\n",
        "            # find k nearest hit points\n",
        "            if distance_sort[i][2] == y[idx]:\n",
        "                if len(near_hit) < k:\n",
        "                    near_hit.append(distance_sort[i][1])\n",
        "                elif len(near_hit) == k:\n",
        "                    stop_dict[y[idx]] = 1\n",
        "            else:\n",
        "                # find k nearest miss points for each label\n",
        "                if len(near_miss[distance_sort[i][2]]) < k:\n",
        "                    near_miss[distance_sort[i][2]].append(distance_sort[i][1])\n",
        "                else:\n",
        "                    if len(near_miss[distance_sort[i][2]]) == k:\n",
        "                        stop_dict[distance_sort[i][2]] = 1\n",
        "            stop = True\n",
        "            for (key, value) in stop_dict.items():\n",
        "                    if value != 1:\n",
        "                        stop = False\n",
        "            if stop:\n",
        "                break\n",
        "\n",
        "        # update reliefF score\n",
        "        near_hit_term = np.zeros(n_features)\n",
        "        for ele in near_hit:\n",
        "            near_hit_term = np.array(abs(self_fea-X[ele, :]))+np.array(near_hit_term)\n",
        "\n",
        "        near_miss_term = dict()\n",
        "        for (label, miss_list) in near_miss.items():\n",
        "            near_miss_term[label] = np.zeros(n_features)\n",
        "            for ele in miss_list:\n",
        "                near_miss_term[label] = np.array(abs(self_fea-X[ele, :]))+np.array(near_miss_term[label])\n",
        "            score += near_miss_term[label]/(k*p_dict[label])\n",
        "        score -= near_hit_term/k\n",
        "    return score\n",
        "\n",
        "\n",
        "def feature_ranking(score):\n",
        "    \"\"\"\n",
        "    Rank features in descending order according to reliefF score, the higher the reliefF score, the more important the\n",
        "    feature is\n",
        "    \"\"\"\n",
        "    idx = np.argsort(score, 0)\n",
        "    return idx[::-1]\n",
        "def selected_features(X, score):\n",
        "  ranked_features = feature_ranking(score)\n",
        "  sel_feat = []\n",
        "  for i in range(X.shape[1]):\n",
        "    if(ranked_features[i]>0):\n",
        "      sel_feat.append(ranked_features[i])\n",
        "    else:\n",
        "      break\n",
        "  return X.columns[np.array(sel_feat)]\n"
      ],
      "metadata": {
        "id": "od1W19upYUic"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##symmetrical uncertainty\n",
        "def SU(df, X,Y):\n",
        "  if(Y=='activity'):\n",
        "    IG = mutual_info_classif(np.transpose(np.array([df[X]])), df[Y]).item()\n",
        "    H_Y = entropy(df[Y])\n",
        "  else:\n",
        "    IG = mutual_info_regression(np.transpose(np.array([df[X]])), df[Y]).item()\n",
        "    H_Y = differential_entropy(df[Y])\n",
        "  H_X = differential_entropy(df[X])\n",
        "  su = ((2.0*IG)/(H_X+H_Y))\n",
        "  #print(IG,H_X,H_Y, su)\n",
        "  return su\n",
        "  \n",
        "#Fast Correlation Based Filter\n",
        "def FCBF(df, features, C):\n",
        "  thresh = 0.000001\n",
        "  N = len(features)\n",
        "  S_list = {}\n",
        "  for i in range(N):\n",
        "    val = SU(df, features[i], C)\n",
        "    if(val> thresh):\n",
        "      S_list[features[i]] = val\n",
        "  S_list = pd.Series(S_list).sort_values(ascending=False)\n",
        "  no_features = S_list.shape[0]\n",
        "  a_list = np.ones(no_features)\n",
        "  for i in range(no_features):\n",
        "    if(a_list[i]==1):\n",
        "      Fp = S_list.index[i]\n",
        "      for j in range(i+1,no_features):\n",
        "        if(a_list[j]==1):\n",
        "          Fq = S_list.index[j]\n",
        "          if(SU(df, Fp,Fq) >= S_list[j]):\n",
        "            print(f\"{j} has been eleminated while in {i}\")\n",
        "            a_list[j]=0\n",
        "  idx = np.where(a_list==1)[0]\n",
        "  return S_list.index[idx]\n",
        "\n",
        "def random_forest_feature_selection(X_train, y_train):\n",
        "  sel = SelectFromModel(RandomForestClassifier(n_estimators = 100))\n",
        "  sel.fit(X_train, y_train)\n",
        "  sel.get_support()\n",
        "  selected_features_rf= X_train.columns[(sel.get_support())].values\n",
        "  return selected_features_rf\n",
        "\n",
        "def reliefF_feature_selection(X_train, y_train):\n",
        "  score = reliefF(X_train.to_numpy(),y_train.to_numpy())\n",
        "  selected_features_relief = selected_features(X_train,score).values\n",
        "  return selected_features_relief\n",
        "\n",
        "def genetic_feature_selection(X_train, y_train):\n",
        "  estimator = DecisionTreeClassifier()\n",
        "  model = GeneticSelectionCV(\n",
        "      estimator, cv=5, verbose=0,\n",
        "      scoring=\"accuracy\", max_features=100,\n",
        "      n_population=100, crossover_proba=0.5,\n",
        "      mutation_proba=0.2, n_generations=50,\n",
        "      crossover_independent_proba=0.5,\n",
        "      mutation_independent_proba=0.04,\n",
        "      tournament_size=3, n_gen_no_change=10,\n",
        "      caching=True, n_jobs=-1)\n",
        "  model = model.fit(X_train,y_train)\n",
        "  selected_features_genetic = X_train.columns[model._get_support_mask()].values\n",
        "  return selected_features_genetic\n",
        "\n",
        "def mutual_information_feature_selection(X_train, y_train):\n",
        "  mi_scores = mutual_info_regression(X_train, y_train, discrete_features=False)\n",
        "  mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
        "  mi_scores = mi_scores.sort_values(ascending=False)\n",
        "  selected_features_info_gain = mi_scores[mi_scores>0.5].index.values\n",
        "  return selected_features_info_gain\n",
        "\n",
        "def chi2_feature_selection(X_train1,y_train):\n",
        "  scaler = MinMaxScaler()\n",
        "  X_train1 = scaler.fit_transform(X_train)\n",
        "  from sklearn.feature_selection import chi2\n",
        "  chi_scores = chi2(X_train1,y_train)\n",
        "  p_values = pd.Series(chi_scores[1],index = X.columns)\n",
        "  p_values.sort_values(ascending = False , inplace = True)\n",
        "  selected_features_chi = p_values[p_values>0.5].index.values\n",
        "  return selected_features_chi"
      ],
      "metadata": {
        "id": "c4MRBs1NRCjX"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ECFS(df,X_train,y_train):\n",
        "  selected_feature_list = [random_forest_feature_selection(X_train,y_train),\n",
        "                           reliefF_feature_selection(X_train,y_train), \n",
        "                           genetic_feature_selection(X_train,y_train), \n",
        "                           mutual_information_feature_selection(X_train,y_train), \n",
        "                           chi2_feature_selection(X_train,y_train)]\n",
        "  s = set()\n",
        "  df_train = df.iloc[X_train.index]\n",
        "  for i in range(5):\n",
        "    for j in range(len(selected_feature_list[i])):\n",
        "      s.add(selected_feature_list[i][j])\n",
        "  final_list = []\n",
        "  ensemble_list = []\n",
        "  for feat in s:\n",
        "    cnt = 0\n",
        "    for j in range(5):\n",
        "      if(feat in selected_feature_list[j]):\n",
        "        cnt+=1\n",
        "    if(cnt>=4):\n",
        "      final_list.append(feat)\n",
        "    else:\n",
        "      ensemble_list.append(feat)\n",
        "  sel = FCBF(df_train, ensemble_list, 'activity')\n",
        "  final_list.extend(sel.values.tolist())\n",
        "  return final_list"
      ],
      "metadata": {
        "id": "EvmtcTLd8Rig"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_feat = ECFS(df, X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3NsnerKMvcG",
        "outputId": "ad28ea81-1a45-4644-acab-224567420a89"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "333 has been eleminated while in 0\n",
            "337 has been eleminated while in 0\n",
            "338 has been eleminated while in 0\n",
            "340 has been eleminated while in 0\n",
            "343 has been eleminated while in 0\n",
            "345 has been eleminated while in 0\n",
            "327 has been eleminated while in 1\n",
            "334 has been eleminated while in 1\n",
            "344 has been eleminated while in 1\n",
            "339 has been eleminated while in 2\n",
            "342 has been eleminated while in 2\n",
            "325 has been eleminated while in 5\n",
            "213 has been eleminated while in 16\n",
            "297 has been eleminated while in 16\n",
            "318 has been eleminated while in 18\n",
            "323 has been eleminated while in 18\n",
            "245 has been eleminated while in 19\n",
            "298 has been eleminated while in 19\n",
            "133 has been eleminated while in 22\n",
            "237 has been eleminated while in 22\n",
            "255 has been eleminated while in 22\n",
            "264 has been eleminated while in 22\n",
            "290 has been eleminated while in 22\n",
            "303 has been eleminated while in 22\n",
            "305 has been eleminated while in 22\n",
            "306 has been eleminated while in 22\n",
            "307 has been eleminated while in 22\n",
            "308 has been eleminated while in 22\n",
            "311 has been eleminated while in 22\n",
            "326 has been eleminated while in 22\n",
            "330 has been eleminated while in 22\n",
            "341 has been eleminated while in 23\n",
            "70 has been eleminated while in 26\n",
            "92 has been eleminated while in 26\n",
            "94 has been eleminated while in 26\n",
            "98 has been eleminated while in 26\n",
            "111 has been eleminated while in 26\n",
            "113 has been eleminated while in 26\n",
            "122 has been eleminated while in 26\n",
            "159 has been eleminated while in 26\n",
            "168 has been eleminated while in 26\n",
            "191 has been eleminated while in 26\n",
            "206 has been eleminated while in 26\n",
            "221 has been eleminated while in 26\n",
            "228 has been eleminated while in 26\n",
            "229 has been eleminated while in 26\n",
            "254 has been eleminated while in 26\n",
            "262 has been eleminated while in 26\n",
            "263 has been eleminated while in 26\n",
            "265 has been eleminated while in 26\n",
            "267 has been eleminated while in 26\n",
            "268 has been eleminated while in 26\n",
            "279 has been eleminated while in 26\n",
            "288 has been eleminated while in 26\n",
            "295 has been eleminated while in 26\n",
            "315 has been eleminated while in 26\n",
            "54 has been eleminated while in 34\n",
            "95 has been eleminated while in 34\n",
            "145 has been eleminated while in 34\n",
            "149 has been eleminated while in 34\n",
            "166 has been eleminated while in 34\n",
            "169 has been eleminated while in 34\n",
            "176 has been eleminated while in 34\n",
            "180 has been eleminated while in 34\n",
            "192 has been eleminated while in 34\n",
            "193 has been eleminated while in 34\n",
            "198 has been eleminated while in 34\n",
            "208 has been eleminated while in 34\n",
            "211 has been eleminated while in 34\n",
            "212 has been eleminated while in 34\n",
            "217 has been eleminated while in 34\n",
            "241 has been eleminated while in 34\n",
            "289 has been eleminated while in 34\n",
            "300 has been eleminated while in 34\n",
            "304 has been eleminated while in 34\n",
            "310 has been eleminated while in 34\n",
            "312 has been eleminated while in 34\n",
            "319 has been eleminated while in 34\n",
            "320 has been eleminated while in 34\n",
            "321 has been eleminated while in 34\n",
            "324 has been eleminated while in 34\n",
            "48 has been eleminated while in 35\n",
            "50 has been eleminated while in 35\n",
            "56 has been eleminated while in 35\n",
            "61 has been eleminated while in 35\n",
            "67 has been eleminated while in 35\n",
            "73 has been eleminated while in 35\n",
            "82 has been eleminated while in 35\n",
            "97 has been eleminated while in 35\n",
            "106 has been eleminated while in 35\n",
            "332 has been eleminated while in 37\n",
            "329 has been eleminated while in 40\n",
            "64 has been eleminated while in 52\n",
            "93 has been eleminated while in 52\n",
            "124 has been eleminated while in 52\n",
            "132 has been eleminated while in 52\n",
            "189 has been eleminated while in 52\n",
            "66 has been eleminated while in 58\n",
            "335 has been eleminated while in 72\n",
            "336 has been eleminated while in 72\n",
            "301 has been eleminated while in 88\n",
            "328 has been eleminated while in 88\n",
            "252 has been eleminated while in 99\n",
            "281 has been eleminated while in 102\n",
            "283 has been eleminated while in 102\n",
            "292 has been eleminated while in 105\n",
            "317 has been eleminated while in 112\n",
            "224 has been eleminated while in 209\n",
            "227 has been eleminated while in 209\n",
            "234 has been eleminated while in 209\n",
            "236 has been eleminated while in 209\n",
            "238 has been eleminated while in 209\n",
            "242 has been eleminated while in 209\n",
            "244 has been eleminated while in 209\n",
            "246 has been eleminated while in 209\n",
            "247 has been eleminated while in 209\n",
            "248 has been eleminated while in 209\n",
            "249 has been eleminated while in 209\n",
            "251 has been eleminated while in 209\n",
            "253 has been eleminated while in 209\n",
            "257 has been eleminated while in 209\n",
            "266 has been eleminated while in 209\n",
            "271 has been eleminated while in 209\n",
            "276 has been eleminated while in 209\n",
            "277 has been eleminated while in 209\n",
            "278 has been eleminated while in 209\n",
            "280 has been eleminated while in 209\n",
            "282 has been eleminated while in 209\n",
            "285 has been eleminated while in 209\n",
            "286 has been eleminated while in 209\n",
            "287 has been eleminated while in 209\n",
            "291 has been eleminated while in 209\n",
            "294 has been eleminated while in 209\n",
            "296 has been eleminated while in 209\n",
            "302 has been eleminated while in 209\n",
            "274 has been eleminated while in 215\n",
            "275 has been eleminated while in 215\n",
            "293 has been eleminated while in 232\n",
            "309 has been eleminated while in 256\n",
            "313 has been eleminated while in 272\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(selected_feat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_bN1CL0pzir",
        "outputId": "b3cabd8d-8f76-40ec-83ed-03546192be82"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "230"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train[selected_feat]\n",
        "X_test = X_test[selected_feat]\n",
        "X_val = X_val[selected_feat]"
      ],
      "metadata": {
        "id": "70NuNcWkaa5k"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "FG4M_nyqN1qy"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
        "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
        "X_val = torch.from_numpy(X_val.astype(np.float32))\n",
        "y_train =  torch.tensor(y_train.values.astype(np.float32))-1\n",
        "y_test =  torch.tensor(y_test.values.astype(np.float32))-1\n",
        "y_val =  torch.tensor(y_val.values.astype(np.float32))-1"
      ],
      "metadata": {
        "id": "77UPtOS7X1zh"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DNN(nn.Module):\n",
        "    def __init__(self,input_size,output_size):\n",
        "        super(DNN,self).__init__()\n",
        "        self.hidden1 = nn.Linear(input_size,128)\n",
        "        self.hidden2 = nn.Linear(128,64)\n",
        "        self.hidden3 = nn.Linear(64,32)\n",
        "        self.output = nn.Linear(32,output_size)\n",
        "        self.softmax = F.softmax\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(p=0.2)\n",
        "        self.batchnorm1 = nn.BatchNorm1d(128)\n",
        "        self.batchnorm2 = nn.BatchNorm1d(64)\n",
        "        self.batchnorm3 = nn.BatchNorm1d(32)\n",
        "    \n",
        "    def forward(self,x):\n",
        "        out = self.hidden1(x)\n",
        "        out = self.batchnorm1(out)\n",
        "        out = self.relu(out)\n",
        "        \n",
        "        out = self.hidden2(out)\n",
        "        out = self.batchnorm2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.dropout(out)\n",
        "\n",
        "        out = self.hidden3(out)\n",
        "        out = self.batchnorm3(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.dropout(out)\n",
        "\n",
        "        out = self.output(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "fnn0yDuHX7nH"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = X_train.shape[1]\n",
        "output_size = torch.unique(y_train).shape[0]\n",
        "learning_rate = 0.001\n",
        "num_epochs = 1001\n",
        "batch_size = 163\n",
        "no_of_samples = X_train.shape[0]"
      ],
      "metadata": {
        "id": "IXXVqyhhX-vh"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss(reduction='sum')"
      ],
      "metadata": {
        "id": "R55egUmIYBDf"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_batch(X,y,batch_size,step):\n",
        "  l = (step-1)*batch_size\n",
        "  return X[l:(l+batch_size)],y[l:min(no_of_samples,l+batch_size)]"
      ],
      "metadata": {
        "id": "TMx87EXTYEnV"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_lr = None\n",
        "best_loss = 100000\n",
        "best_model = None\n",
        "best_train_loss = None\n",
        "best_val_loss = None\n",
        "for lr in [0.0005,0.001,0.003,0.005,0.01]:\n",
        "  print(f\"Learning rate: {lr}:\")\n",
        "  net = DNN(input_size, output_size)\n",
        "  optimizer = torch.optim.SGD(net.parameters(), lr=lr)  \n",
        "  train_loss = []\n",
        "  val_loss = []\n",
        "  for epoch in range(num_epochs):\n",
        "    step = 1\n",
        "    while(batch_size*step<=no_of_samples):\n",
        "      x,y =  extract_batch(X_train,y_train, batch_size, step)\n",
        "      # Forward Propagation\n",
        "      y_predicted = net(x)\n",
        "      loss = criterion(y_predicted,  torch.tensor(y, dtype=torch.long))\n",
        "      #loss = cross_entropy(y_predicted,y)\n",
        "      # Backward propagation and update\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      # Performing zero grad before new step\n",
        "      optimizer.zero_grad()\n",
        "      step = step+1\n",
        "    train_loss.append(criterion( net(X_train),  torch.tensor(y_train, dtype=torch.long)).item()) \n",
        "    val_loss.append(criterion( net(X_val),  torch.tensor(y_val, dtype=torch.long)).item())\n",
        "      #appending the loss to the loss list\n",
        "    if(epoch%100==0):\n",
        "      print(f'epoch: {epoch}, loss = {train_loss[-1]}')\n",
        "  val_ls = sum(val_loss)/len(val_loss)\n",
        "  if(val_ls<=best_loss):\n",
        "    best_loss = val_ls\n",
        "    best_lr = lr\n",
        "    best_model = net\n",
        "    best_val_loss = val_loss\n",
        "    best_train_loss = train_loss\n",
        "print(f\"Best_lr:{best_lr}\\nBest_loss:{best_loss}\")\n"
      ],
      "metadata": {
        "id": "6jKgwWbDYF5H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef25bd47-326b-4416-e8be-941d5418bbe7"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate: 0.0005:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, loss = 1930.5953369140625\n",
            "epoch: 100, loss = 73.6736831665039\n",
            "epoch: 200, loss = 40.500858306884766\n",
            "epoch: 300, loss = 25.613262176513672\n",
            "epoch: 400, loss = 17.949460983276367\n",
            "epoch: 500, loss = 18.0140380859375\n",
            "epoch: 600, loss = 19.926040649414062\n",
            "epoch: 700, loss = 23.79229736328125\n",
            "epoch: 800, loss = 10.18874740600586\n",
            "epoch: 900, loss = 14.73678970336914\n",
            "epoch: 1000, loss = 10.17471694946289\n",
            "Learning rate: 0.001:\n",
            "epoch: 0, loss = 1818.8587646484375\n",
            "epoch: 100, loss = 47.091087341308594\n",
            "epoch: 200, loss = 23.346324920654297\n",
            "epoch: 300, loss = 17.62371063232422\n",
            "epoch: 400, loss = 9.39721393585205\n",
            "epoch: 500, loss = 12.773235321044922\n",
            "epoch: 600, loss = 10.903157234191895\n",
            "epoch: 700, loss = 7.879705429077148\n",
            "epoch: 800, loss = 13.58222484588623\n",
            "epoch: 900, loss = 12.343847274780273\n",
            "epoch: 1000, loss = 5.046199321746826\n",
            "Learning rate: 0.003:\n",
            "epoch: 0, loss = 1507.453857421875\n",
            "epoch: 100, loss = 29.234331130981445\n",
            "epoch: 200, loss = 13.636115074157715\n",
            "epoch: 300, loss = 9.180954933166504\n",
            "epoch: 400, loss = 4.001505374908447\n",
            "epoch: 500, loss = 2.014096975326538\n",
            "epoch: 600, loss = 4.766219139099121\n",
            "epoch: 700, loss = 8.05095386505127\n",
            "epoch: 800, loss = 8.755666732788086\n",
            "epoch: 900, loss = 3.072091817855835\n",
            "epoch: 1000, loss = 4.506794452667236\n",
            "Learning rate: 0.005:\n",
            "epoch: 0, loss = 1316.28759765625\n",
            "epoch: 100, loss = 27.948566436767578\n",
            "epoch: 200, loss = 10.791770935058594\n",
            "epoch: 300, loss = 6.814704895019531\n",
            "epoch: 400, loss = 12.211572647094727\n",
            "epoch: 500, loss = 15.498001098632812\n",
            "epoch: 600, loss = 9.804162979125977\n",
            "epoch: 700, loss = 16.87218475341797\n",
            "epoch: 800, loss = 2.238445997238159\n",
            "epoch: 900, loss = 14.76917839050293\n",
            "epoch: 1000, loss = 15.487092971801758\n",
            "Learning rate: 0.01:\n",
            "epoch: 0, loss = 1175.1929931640625\n",
            "epoch: 100, loss = 13.220555305480957\n",
            "epoch: 200, loss = 9.42796516418457\n",
            "epoch: 300, loss = 3.593236207962036\n",
            "epoch: 400, loss = 8.001248359680176\n",
            "epoch: 500, loss = 9.310470581054688\n",
            "epoch: 600, loss = 4.365546226501465\n",
            "epoch: 700, loss = 2.2543351650238037\n",
            "epoch: 800, loss = 6.43176794052124\n",
            "epoch: 900, loss = 2.4833505153656006\n",
            "epoch: 1000, loss = 3.9213945865631104\n",
            "Best_lr:0.003\n",
            "Best_loss:5.418840068724606\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def multi_acc(y_pred, y_test):\n",
        "    y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n",
        "    _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)   \n",
        "    correct_pred = (y_pred_tags == y_test).float()\n",
        "    acc = correct_pred.sum()*1.0 / len(correct_pred)\n",
        "    acc = acc * 100\n",
        "    return acc"
      ],
      "metadata": {
        "id": "QeLV165gYHnA"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = best_model(X_test)\n",
        "acc = multi_acc(y_pred, y_test)\n",
        "print(f\"Test accuracy is {(acc):.2f}%\")"
      ],
      "metadata": {
        "id": "lj9jd9CtYI_T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50185446-42a6-4cb2-b0e9-8c549ab2625b"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy is 97.71%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "sns.lineplot(range(1001),best_train_loss)\n",
        "plt.ylabel(\"Total Loss\")\n",
        "plt.xlabel(\"No of Epochs\")"
      ],
      "metadata": {
        "id": "jziLsqKydAkd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "outputId": "5fff82e7-a23a-4cb1-853c-ff7b84761b70"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'No of Epochs')"
            ]
          },
          "metadata": {},
          "execution_count": 157
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.lineplot(range(1001),best_val_loss)\n",
        "plt.ylabel(\"Total Loss\")\n",
        "plt.xlabel(\"No of Epochs\")"
      ],
      "metadata": {
        "id": "XTMaVenpzRUk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "outputId": "be3888d4-405b-45dd-eee0-1edd5a07ba01"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'No of Epochs')"
            ]
          },
          "metadata": {},
          "execution_count": 158
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M8k-dT7sWQmK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}